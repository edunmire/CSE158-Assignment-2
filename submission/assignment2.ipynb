{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab71970b",
   "metadata": {},
   "source": [
    "# Rating Prediction of Cafe on Google Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf582ce",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc5e4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17eacd590>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "from functools import partial\n",
    "from datetime import datetime, timezone\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "import ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bf28f2",
   "metadata": {},
   "source": [
    "### Downloading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32962626",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = \"./datasets/raw/meta-California.json.gz\"\n",
    "meta_keys = [\"gmap_id\", \"name\", \"latitude\", \"longitude\", \"category\", \"avg_rating\", \"num_of_reviews\", \"price\", \"hours\"]\n",
    "\n",
    "review_path = \"./datasets/raw/review-California.json.gz\"\n",
    "review_keys = [\"gmap_id\", \"user_id\", \"name\", \"time\", \"rating\"]\n",
    "\n",
    "total_reviews = 70529977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18f7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_meta_data():\n",
    "    url = \"https://mcauleylab.ucsd.edu/public_datasets/gdrive/googlelocal/meta-California.json.gz\"\n",
    "    res = requests.get(url, stream=True)\n",
    "\n",
    "    with open(meta_path, \"wb\") as f:\n",
    "        f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7294699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_review_data():\n",
    "    url = \"https://mcauleylab.ucsd.edu/public_datasets/gdrive/googlelocal/review-California.json.gz\"\n",
    "    res = requests.get(url, stream=True)\n",
    "\n",
    "    with open(review_path, \"wb\") as f:\n",
    "        f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ffd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./datasets/raw\", exist_ok=True)\n",
    "os.makedirs(\"./datasets/processed\", exist_ok=True)\n",
    "\n",
    "if not os.path.exists(meta_path):\n",
    "    download_meta_data()\n",
    "\n",
    "if not os.path.exists(\"./datasets/raw/review-California.json.gz\"):\n",
    "    download_review_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad61ce8",
   "metadata": {},
   "source": [
    "### Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb43ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, \"r\")\n",
    "    for l in g:\n",
    "        yield json.loads(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8214245",
   "metadata": {},
   "source": [
    "Processing business data to extract Cafes we want to focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6829fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I reused my code from COGS108 project to process dataset.\n",
    "\n",
    "def get_cafe_categories():\n",
    "    categories = []\n",
    "    for business in parse(meta_path):\n",
    "        if business[\"category\"] is not None:\n",
    "            categories += business[\"category\"]\n",
    "\n",
    "    categories = np.array(categories)\n",
    "    unique = np.unique(categories)\n",
    "\n",
    "    cafe_categories = [str(category) for category in unique if \"cafe\" in category.lower() or \"coffee\" in category.lower()]\n",
    "    print(f\"The number of categories containting 'cafe' substring is {len(cafe_categories)}\")\n",
    "    print(cafe_categories)\n",
    "\n",
    "    with open(f\"./datasets/processed/cafe_categories.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(cafe_categories))\n",
    "\n",
    "def filter_by_category(data, categories):\n",
    "    category = data.get(\"category\", None)\n",
    "    if category is None:\n",
    "        return False\n",
    "\n",
    "    return len(set(category) & categories) != 0\n",
    "\n",
    "def filter_by_num_reviews(data, min_num_reviews):\n",
    "    return data[\"num_of_reviews\"] >= min_num_reviews\n",
    "\n",
    "def filter_raw_business_data(filters):\n",
    "    businesses = []\n",
    "    for business in parse(meta_path):\n",
    "        if all([f(data=business) for f in filters]):\n",
    "            business = {key: business.get(key, None) for key in meta_keys}\n",
    "            businesses.append(business)\n",
    "\n",
    "    print(f\"We obtained total of {len(businesses)} after filtering\")\n",
    "\n",
    "    df = pd.DataFrame(businesses)\n",
    "    df.to_csv(f\"./datasets/processed/cafes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580be6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./datasets/processed/cafe_categories.txt\"):\n",
    "        get_cafe_categories()\n",
    "\n",
    "if not os.path.exists(\"./datasets/processed/cafes.csv\"):\n",
    "    min_num_reviews = 100\n",
    "\n",
    "    with open(\"./datasets/processed/cafe_categories.txt\", \"r\") as f:\n",
    "        cafe_categories = set(f.read().split(\"\\n\"))\n",
    "\n",
    "    cafe_filter = partial(filter_by_category, categories=cafe_categories)\n",
    "    num_reviews_filter = partial(filter_by_num_reviews, min_num_reviews=min_num_reviews)\n",
    "\n",
    "    filter_raw_business_data([cafe_filter, num_reviews_filter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850feefc",
   "metadata": {},
   "source": [
    "Processing review data to extract reviews we want to focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb99b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I reused my code from COGS108 project to process dataset.\n",
    "\n",
    "def filter_by_gmap_id(data, gmap_ids):\n",
    "    gmap_id = data.get(\"gmap_id\", None)\n",
    "    if gmap_id is None:\n",
    "        return False\n",
    "\n",
    "    return gmap_id in gmap_ids\n",
    "\n",
    "def filter_raw_review_data(filters):\n",
    "    reviews = []\n",
    "\n",
    "    for review in tqdm.tqdm(parse(review_path), total=total_reviews):\n",
    "        if all([f(data=review) for f in filters]):\n",
    "            review = {key: review.get(key, None) for key in review_keys}\n",
    "            review[\"review_id\"] = f\"{review['user_id']}_{review['gmap_id']}\"\n",
    "            reviews.append(review)\n",
    "\n",
    "    print(f\"We obtained total of {len(reviews)} after filtering\")\n",
    "    df = pd.DataFrame(reviews)\n",
    "    df.to_csv(\"./datasets/raw/cafe_reviews.csv\", index=False)\n",
    "\n",
    "def extract_user_ids(reviews, min_num_reviews):\n",
    "    user_ids = reviews[\"user_id\"].dropna().values\n",
    "    unique, counts = np.unique(np.array(user_ids), return_counts=True)\n",
    "    users = pd.DataFrame({\"user_id\": unique, \"num_reviews\": counts})\n",
    "\n",
    "    users = users[users[\"num_reviews\"] >= min_num_reviews].reset_index(drop=True)\n",
    "    print(f\"We extracted {users.shape[0]} users after filtering.\")\n",
    "\n",
    "    users.to_csv(\"./datasets/processed/users.csv\", index=False)\n",
    "\n",
    "def filter_by_user_ids(reviews, user_ids):\n",
    "    reviews = reviews[reviews[\"user_id\"].isin(user_ids)]\n",
    "\n",
    "    print(f\"We extracted {reviews.shape[0]} reviews after filtering.\")\n",
    "    reviews.to_csv(\"./datasets/processed/reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89381faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./datasets/raw/cafe_reviews.csv\"):\n",
    "    gmap_ids = set(pd.read_csv(\"./datasets/processed/cafes.csv\")[\"gmap_id\"].values)\n",
    "    gmap_id_filter = partial(filter_by_gmap_id, gmap_ids=gmap_ids)\n",
    "    filter_raw_review_data([gmap_id_filter])\n",
    "\n",
    "if not os.path.exists(\"./datasets/processed/users.csv\"):\n",
    "    print(\"Start processing user data\")\n",
    "    reviews = pd.read_csv(\"./datasets/raw/cafe_reviews.csv\")\n",
    "    min_num_reviews = 20\n",
    "    extract_user_ids(reviews, min_num_reviews)\n",
    "\n",
    "if not os.path.exists(\"./datasets/processed/reviews.csv\"):\n",
    "    print(\"Start filtering review data\")\n",
    "    reviews = pd.read_csv(\"./datasets/raw/cafe_reviews.csv\")\n",
    "    user_ids = pd.read_csv(\"./datasets/processed/users.csv\")[\"user_id\"].values\n",
    "    filter_by_user_ids(reviews, user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f879f6",
   "metadata": {},
   "source": [
    "Split dataset into train, validation, and test so that we can evaluate models with unseen data. However, due to the design of the model which relies on pre-defined list of user and cafes, we need to split randomly without stratifying based on users or cafes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e5b56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_reviews():\n",
    "    file_name = \"./datasets/processed/reviews.csv\"\n",
    "    reviews = pd.read_csv(file_name).sample(frac=1, random_state=42)\n",
    "\n",
    "    valid_size = int(reviews.shape[0] * 0.1)\n",
    "    test_size = int(reviews.shape[0] * 0.1)\n",
    "\n",
    "    valid_reviews = reviews.iloc[:valid_size].reset_index(drop=True)\n",
    "    test_reviews = reviews.iloc[valid_size: valid_size + test_size].reset_index(drop=True)\n",
    "    train_reviews = reviews.iloc[valid_size + test_size:].reset_index(drop=True)\n",
    "\n",
    "    print(f\"train: {train_reviews.shape[0]} / valid: {valid_reviews.shape[0]} / test: {test_reviews.shape[0]}\")\n",
    "\n",
    "    os.makedirs(\"./datasets/splits\", exist_ok=True)\n",
    "\n",
    "    train_reviews.to_csv(\"./datasets/splits/train.csv\", index=False)\n",
    "    valid_reviews.to_csv(\"./datasets/splits/valid.csv\", index=False)\n",
    "    test_reviews.to_csv(\"./datasets/splits/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "340db926",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./datasets/splits/train.csv\"):\n",
    "    split_reviews()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c40b58",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ca1e86",
   "metadata": {},
   "source": [
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4943c9",
   "metadata": {},
   "source": [
    "## Rating Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedc8938",
   "metadata": {},
   "source": [
    "### Modeling Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a4c83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ee087cc",
   "metadata": {},
   "source": [
    "### Feature Matrix Consturction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2e889",
   "metadata": {},
   "source": [
    "We construct dictionaries converting followings:\n",
    "- `user_id` to index of onehot vector for user.\n",
    "- `gmap_id` to index of onehot vector for cafe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3478ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_latent(feat_names):\n",
    "    reviews = pd.read_csv(\"./datasets/processed/reviews.csv\")\n",
    "    cafes = pd.read_csv(\"./datasets/processed/cafes.csv\")\n",
    "\n",
    "    feat_dicts = {}\n",
    "    for name in feat_names:\n",
    "        if name == \"user\":\n",
    "            unique_user_ids = np.sort(np.unique(reviews[\"user_id\"].values))\n",
    "            user2index = {user_id: index for index, user_id in enumerate(unique_user_ids)}\n",
    "            feat_dicts[name] = user2index\n",
    "\n",
    "        elif name == \"cafe\":\n",
    "            unique_gmap_ids = np.sort(np.unique(cafes[\"gmap_id\"]))\n",
    "            cafe2index = {gmap_id: index for index, gmap_id in enumerate(unique_gmap_ids)}\n",
    "            feat_dicts[name] = cafe2index\n",
    "\n",
    "    avg_rating = reviews[\"rating\"].mean()\n",
    "\n",
    "    return feat_dicts, avg_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145895b2",
   "metadata": {},
   "source": [
    "Then, we add preprocessing for unix time of a review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcc001be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding for Unix Time Weekday\n",
    "def unix_weekday_to_onehot(time):\n",
    "    feature_weekday = [0]*7\n",
    "\n",
    "    day = datetime.fromtimestamp(time / 1000, tz=timezone.utc).weekday()\n",
    "    feature_weekday[day] = 1.\n",
    "\n",
    "    return feature_weekday\n",
    "\n",
    "# One Hot Encoding for Unix Time Hour\n",
    "def unix_hour_to_onehot(time):\n",
    "    feature_dayhour = [0]*24\n",
    "\n",
    "    hr = datetime.fromtimestamp(time / 1000, tz=timezone.utc).hour\n",
    "    feature_dayhour[hr] = 1.\n",
    "\n",
    "    return feature_dayhour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dfe59d",
   "metadata": {},
   "source": [
    "Then, we construct PyTorch Dataset. This class is desgined to be flexible about which features to use and it receives a list of feature names in `feat_names` we would use in a model and preprocessed mappings `feat_dicts` we need to map data to onehot vector. We can possibly use following features:\n",
    "- `alpha` is a bias term and we initialize it with global average of rating.\n",
    "- `user` is a user of a review.\n",
    "- `cafe` is a cafe of a review.\n",
    "- `weekday` is a weekday of a week when a review was posted.\n",
    "- `hour` is an hour of a day when a review was posted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c2f4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CafeDatasetLatent(Dataset):\n",
    "    def __init__(self, mode, feat_names, feat_dicts):\n",
    "        self.reviews = pd.read_csv(f\"./datasets/splits/{mode}.csv\").values\n",
    "\n",
    "        self.feat_names = feat_names\n",
    "        self.feat_dicts = feat_dicts\n",
    "\n",
    "    def get_feat_sizes(self):\n",
    "        feat_sizes = {}\n",
    "\n",
    "        for name in self.feat_names:\n",
    "            if name == \"alpha\":\n",
    "                feat_sizes[name] = 1\n",
    "\n",
    "            elif name == \"user\":\n",
    "                feat_sizes[name] = len(self.feat_dicts[name].keys())\n",
    "\n",
    "            elif name == \"cafe\":\n",
    "                feat_sizes[name] = len(self.feat_dicts[name].keys())\n",
    "\n",
    "            elif name == \"weekday\":\n",
    "                feat_sizes[name] = 7\n",
    "\n",
    "            elif name == \"hour\":\n",
    "                feat_sizes[name] = 24\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        return feat_sizes\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.reviews.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        review = self.reviews[index]\n",
    "        feats = []\n",
    "        for name in self.feat_names:\n",
    "            if name == \"alpha\":\n",
    "                feat = torch.ones(1)\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"user\":\n",
    "                feat_dict = self.feat_dicts[name]\n",
    "                feat = torch.zeros(len(feat_dict.keys()))\n",
    "                feat[feat_dict[review[1]]] = 1.\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"cafe\":\n",
    "                feat_dict = self.feat_dicts[name]\n",
    "                feat = torch.zeros(len(feat_dict.keys()))\n",
    "                feat[feat_dict[review[0]]] = 1.\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"weekday\":\n",
    "                feat = torch.tensor(unix_weekday_to_onehot(int(review[3])))\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"hour\":\n",
    "                feat = torch.tensor(unix_hour_to_onehot(int(review[3])))\n",
    "                feats.append(feat)\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        rating = torch.tensor(review[4])\n",
    "\n",
    "        return *feats, rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ca7f2",
   "metadata": {},
   "source": [
    "Next, we construct a model for rating prediction. This class is also designed to be flexible and it receives following arguments:\n",
    "- `name` is a unique identifier of a model.\n",
    "- `dim` is a dimension of latent.\n",
    "- `feat_sizes` is a list of feature sizes which would be used to initialize weights.\n",
    "- `latent_names` is a list of latent feature names which would be used to initialize latents.\n",
    "- `latent_pairs` is a list of tuples which indicate pairs we would calculate dot product in between.\n",
    "- `avg_rating` is a global average rating which is used to initialize alpha.\n",
    "  \n",
    "This model has two sets of parameters:\n",
    "- `weights` is a list of weights for each feature and corresponds to betas in model equation.\n",
    "- `latents` is a list of latents for feature we specified and corresponds to gammas in model equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6535a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatePredictorLatent(nn.Module):\n",
    "    def __init__(self, name, dim, feat_sizes, latent_names, latent_pairs, avg_rating):\n",
    "        super().__init__()\n",
    "\n",
    "        self.name = name\n",
    "        self.num_feats = len(feat_sizes)\n",
    "        self.num_latents = len(latent_names)\n",
    "\n",
    "        self.latent_names = latent_names\n",
    "        self.latent_pairs = latent_pairs\n",
    "\n",
    "        self.latent_indices = []\n",
    "        weights = []\n",
    "        for i, (name, feat_size) in enumerate(feat_sizes.items()):\n",
    "            if name == \"alpha\":\n",
    "                weight = torch.tensor(avg_rating).unsqueeze(0)\n",
    "            else:\n",
    "                weight = torch.zeros(feat_size)\n",
    "            weights.append(nn.Parameter(weight, requires_grad=True))\n",
    "\n",
    "            if name in latent_names:\n",
    "                self.latent_indices.append(i)\n",
    "\n",
    "        self.weights =  nn.ParameterList(weights)\n",
    "\n",
    "        latents = []\n",
    "        for name in latent_names:\n",
    "            feat_size = feat_sizes[name]\n",
    "            latent = torch.randn(feat_size, dim) / dim\n",
    "            latents.append(nn.Parameter(latent, requires_grad=True))\n",
    "\n",
    "        self.latents = nn.ParameterList(latents)\n",
    "\n",
    "    def forward(self, feats):\n",
    "        assert len(feats) == self.num_feats\n",
    "\n",
    "        out = torch.zeros(feats[0].size(0))\n",
    "        for i in range(self.num_feats):\n",
    "            out += torch.einsum(\"bd,d->b\", feats[i], self.weights[i])\n",
    "\n",
    "        gammas = {}\n",
    "        for i in range(self.num_latents):\n",
    "            index = self.latent_indices[i]\n",
    "            gammas[self.latent_names[i]] = torch.einsum(\"bd,di->bi\", feats[index], self.latents[i])\n",
    "\n",
    "        for (latent_i, latent_j) in self.latent_pairs:\n",
    "            out += torch.einsum(\"bi,bi->b\", gammas[latent_i], gammas[latent_j])\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97863d7",
   "metadata": {},
   "source": [
    "Next, we construct a trainer to train a model by using autograd of PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73789ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateTrainerLatent():\n",
    "    def __init__(self, model, lambs, lr, train_dataloader, valid_dataloader, device):\n",
    "        self.model = model\n",
    "        self.lambs = lambs\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.device = device\n",
    "\n",
    "        self.optim =  torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "        train_mses, valid_mses = [], []\n",
    "        for i in range(n_epochs):\n",
    "            train_mse = 0\n",
    "            total = 0\n",
    "\n",
    "            bar = tqdm.tqdm(self.train_dataloader, desc=\"Training Model\")\n",
    "            for feats in bar:\n",
    "                ratings = feats[-1].to(self.device)\n",
    "                feats = [f.to(self.device) for f in feats[:-1]]\n",
    "\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "                pred_ratings = self.model(feats)\n",
    "                mse = self.mse(ratings, pred_ratings)\n",
    "                mse_reg = mse + self.regularizer()\n",
    "\n",
    "                mse_reg.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "                local_batch_size = feats[0].size(0)\n",
    "                train_mse += mse.item() * local_batch_size\n",
    "                total += local_batch_size\n",
    "\n",
    "                bar.set_description(f\"Training Model ({mse.item():.6f})\")\n",
    "\n",
    "            train_mse /= total\n",
    "            valid_mse = self.validate()\n",
    "            print(f\"Step[{i + 1:2d}]: train {train_mse:2.6f} / valid {valid_mse:2.6f}\")\n",
    "\n",
    "            train_mses.append(train_mse)\n",
    "            valid_mses.append(valid_mse)\n",
    "\n",
    "        return train_mses, valid_mses\n",
    "\n",
    "    def validate(self):\n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            mse = 0\n",
    "\n",
    "            for feats in self.valid_dataloader:\n",
    "                ratings = feats[-1].to(self.device)\n",
    "                feats = [f.to(self.device) for f in feats[:-1]]\n",
    "\n",
    "                pred_ratings = self.model(feats)\n",
    "\n",
    "                local_batch_size = feats[0].size(0)\n",
    "                mse += self.mse(ratings, pred_ratings).item() * local_batch_size\n",
    "                total += local_batch_size\n",
    "\n",
    "            return mse / total\n",
    "\n",
    "    def mse(self, y_true, y_pred):\n",
    "        return torch.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "    def regularizer(self):\n",
    "        weight_size = len(self.model.weights)\n",
    "        latent_size = len(self.model.latents)\n",
    "        assert len(self.lambs) == weight_size + latent_size\n",
    "\n",
    "        reg = 0\n",
    "        for i in range(len(self.lambs)):\n",
    "            if i < len(self.model.weights):\n",
    "                reg += self.lambs[i] * torch.mean(self.model.weights[i] ** 2)\n",
    "            else:\n",
    "                dim = self.model.latents[0].size(1)\n",
    "                reg += self.lambs[i] * dim * torch.mean(self.model.latents[i - weight_size] ** 2)\n",
    "\n",
    "        return reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56da837",
   "metadata": {},
   "source": [
    "We record metrics in a file `metrics.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9427ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metrics(name, train, valid):\n",
    "    if os.path.exists(\"./metrics.json\"):\n",
    "        with open(\"./metrics.json\", \"r\") as f:\n",
    "           metrics = json.load(f)\n",
    "    else:\n",
    "        metrics = {}\n",
    "\n",
    "    metrics[name] = {\"metrics\": {\"train\": train, \"valid\": valid}}\n",
    "\n",
    "    with open(\"./metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4f1fc",
   "metadata": {},
   "source": [
    "After a series of experiments, we ended up using the following hyperparamters for all the experiments below:\n",
    "- `n_epoch` is the numer of iterations for training.\n",
    "- `lr` is a learning rate of gradient descent.\n",
    "- `dim` is a dimension of latents if used.\n",
    "- `batch_size` is a batch size of training.\n",
    "- `lamb_dict` is a regularization coefficient for each feature.\n",
    "- `device` is a device we run models on. You can change \"cpu\" to \"cuda\" if you have GPU environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcab1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "lr = 0.01\n",
    "dim = 32\n",
    "batch_size = 2048\n",
    "\n",
    "lamb_dict = {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1}\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38cb49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(name, feat_names, latent_names, latent_pairs):\n",
    "    lambs = [lamb_dict[feat] for feat in feat_names + latent_names]\n",
    "\n",
    "    assert all([((latent_i in latent_names) and (latent_j in latent_names)) for (latent_i, latent_j) in latent_pairs])\n",
    "    assert len(lambs) == len(feat_names) + len(latent_names)\n",
    "\n",
    "    if not os.path.exists(f\"./models/{name}.pt\"):\n",
    "        print(f\"Start training {name}\")\n",
    "\n",
    "        feat_dicts, avg_rating = preprocess_data_latent(feat_names)\n",
    "        train_dataset = CafeDatasetLatent(\"train\", feat_names, feat_dicts)\n",
    "        valid_dataset = CafeDatasetLatent(\"valid\", feat_names, feat_dicts)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        feat_sizes = train_dataset.get_feat_sizes()\n",
    "        model = RatePredictorLatent(name, dim, feat_sizes, latent_names, latent_pairs, avg_rating)\n",
    "\n",
    "        trainer = RateTrainerLatent(model, lambs, lr, train_dataloader, valid_dataloader, device)\n",
    "\n",
    "        train_mses, valid_mses = trainer.train(n_epoch)\n",
    "\n",
    "        os.makedirs(\"./models\", exist_ok=True)\n",
    "        torch.save(model, f\"./models/{name}.pt\")\n",
    "\n",
    "        update_metrics(name, train_mses, valid_mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a1aa0",
   "metadata": {},
   "source": [
    "We train a naive model where we only use features of `user_id` and `cafe` without latents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15f4967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"base\"\n",
    "\n",
    "feat_names = [\"alpha\", \"user\", \"cafe\"]\n",
    "latent_names = []\n",
    "latent_pairs = []\n",
    "\n",
    "train(name, feat_names, latent_names, latent_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594c6c1",
   "metadata": {},
   "source": [
    "Next, we train a naive model with latents for `user` and `cafe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4331ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"latent\"\n",
    "\n",
    "feat_names = [\"alpha\", \"user\", \"cafe\"]\n",
    "latent_names = [\"user\", \"cafe\"]\n",
    "latent_pairs = [(\"user\", \"cafe\")]\n",
    "\n",
    "train(name, feat_names, latent_names, latent_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a50f3",
   "metadata": {},
   "source": [
    "### Testing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e87099",
   "metadata": {},
   "source": [
    "We used three ways to evaluate models as follows:\n",
    "- `mse` is a metric used as an objective for training.\n",
    "- `rmse` is a root of mse which has same scale as predictive variable (rating).\n",
    "- `accuracy` is accuracy of correct discrete rating prediction. Since all reviews have discrete ratings of 1.0, 2.0, 3.0, 4.0 and 5.0, given predictions, we asigned discrete prediction by rounding to nearest integer and calculated accuracy comparing true ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d3e5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(y_true, y_pred):\n",
    "    return torch.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return torch.sqrt(torch.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def discrete_rating(y_pred):\n",
    "    y_pred = torch.clamp(y_pred, min=0, max=5)\n",
    "    y_pred = torch.round(y_pred)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20321989",
   "metadata": {},
   "source": [
    "For testing, we saved results in csv table so that we can compare models easily, which is saved to `./test_results.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d18b7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_test_results(result):\n",
    "    new_result = pd.Series(result).to_frame().T\n",
    "\n",
    "    if os.path.exists(\"./test_results.csv\"):\n",
    "        results = pd.read_csv(\"./test_results.csv\")\n",
    "\n",
    "        duplicate_index = results[\"name\"] == result[\"name\"]\n",
    "        if sum(duplicate_index) == 0:\n",
    "            results = pd.concat([results, new_result]).reset_index(drop=True)\n",
    "        else:\n",
    "            results = results.values\n",
    "            results[duplicate_index] = new_result.values\n",
    "            results = pd.DataFrame(results, columns=new_result.columns)\n",
    "    else:\n",
    "        results = new_result\n",
    "\n",
    "    print(results)\n",
    "    results.to_csv(\"./test_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809595f",
   "metadata": {},
   "source": [
    "First we evaluate two baseline models:\n",
    "- `MostCommon` just returns most common discrete rating `5`.\n",
    "- `Naive` just returns a global average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1807c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostCommon(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        reviews = pd.read_csv(\"./datasets/splits/test.csv\")\n",
    "\n",
    "        ratings, counts = np.unique(reviews[\"rating\"], return_counts=True)\n",
    "        self.most_common = torch.tensor(ratings[np.argmax(counts)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.most_common.repeat(x[0].size(0))\n",
    "\n",
    "class Naive(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        reviews = pd.read_csv(\"./datasets/splits/test.csv\")\n",
    "        self.average = torch.tensor(np.mean(reviews[\"rating\"]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.average.repeat(x[0].size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726c4a1",
   "metadata": {},
   "source": [
    "The following a function to run models on test dataset and save results into `test_results.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8abf6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(name, feat_names):\n",
    "    if name == \"most_common\":\n",
    "        model = MostCommon()\n",
    "    elif name == \"naive\":\n",
    "        model = Naive()\n",
    "    else:\n",
    "        model = torch.load(f\"./models/{name}.pt\", weights_only=False)\n",
    "\n",
    "    feat_dicts, _ = preprocess_data_latent(feat_names)\n",
    "\n",
    "    test_dataset = CafeDatasetLatent(\"test\", feat_names, feat_dicts)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        mse, rmse = 0, 0\n",
    "        n_corrects = 0\n",
    "\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        for feats in tqdm.tqdm(test_dataloader):\n",
    "            ratings = feats[-1].to(device)\n",
    "            feats = [f.to(device) for f in feats[:-1]]\n",
    "\n",
    "            pred_ratings = model(feats)\n",
    "\n",
    "            local_batch_size = feats[0].size(0)\n",
    "            mse += calculate_mse(ratings, pred_ratings).item() * local_batch_size\n",
    "            rmse += calculate_rmse(ratings, pred_ratings).item() * local_batch_size\n",
    "\n",
    "            pred_discrete = discrete_rating(pred_ratings)\n",
    "\n",
    "            n_corrects += torch.sum(pred_discrete == ratings).item()\n",
    "            total += local_batch_size\n",
    "\n",
    "        test_mse = mse / total\n",
    "        test_rmse = rmse / total\n",
    "        test_accuracy = n_corrects / total\n",
    "\n",
    "        result = {\"name\": name, \"mse\": test_mse, \"rmse\": test_rmse, \"accuracy\": test_accuracy}\n",
    "        update_test_results(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1412f78b",
   "metadata": {},
   "source": [
    "Run MostCommon and Naive first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb2336c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 112.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          name       mse      rmse  accuracy\n",
      "0  most_common  1.594156  1.262308  0.523571\n",
      "1        naive  1.006339  1.002901   0.28008\n",
      "2         base  0.687413  0.828871  0.555235\n",
      "3       latent  0.680835  0.824916  0.563493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"most_common\"\n",
    "feat_names = [\"alpha\"]\n",
    "test_model(name, feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25d6090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 75.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          name       mse      rmse  accuracy\n",
      "0  most_common  1.594156  1.262308  0.523571\n",
      "1        naive  1.006339  1.003055   0.28008\n",
      "2         base  0.687413  0.828871  0.555235\n",
      "3       latent  0.680835  0.824916  0.563493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"naive\"\n",
    "feat_names = [\"alpha\"]\n",
    "test_model(name, feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6128075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          name       mse      rmse  accuracy\n",
      "0  most_common  1.594156  1.262308  0.523571\n",
      "1        naive  1.006339  1.003055   0.28008\n",
      "2         base  0.687413  0.828869  0.555235\n",
      "3       latent  0.680835  0.824916  0.563493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"base\"\n",
    "feat_names = [\"alpha\", \"user\", \"cafe\"]\n",
    "test_model(name, feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e35ba7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          name       mse      rmse  accuracy\n",
      "0  most_common  1.594156  1.262308  0.523571\n",
      "1        naive  1.006339  1.003055   0.28008\n",
      "2         base  0.687413  0.828869  0.555235\n",
      "3       latent  0.680835  0.824859  0.563493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"latent\"\n",
    "feat_names = [\"alpha\", \"user\", \"cafe\"]\n",
    "test_model(name, feat_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
