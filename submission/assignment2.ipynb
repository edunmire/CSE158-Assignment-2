{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab71970b",
   "metadata": {},
   "source": [
    "# Rating Prediction of Cafe on Google Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf582ce",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6fc5e4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x178e2f2f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "from functools import partial\n",
    "from datetime import datetime, timezone\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from shapely.geometry import shape, Point\n",
    "from shapely.prepared import prep\n",
    "from functools import lru_cache\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "import ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bf28f2",
   "metadata": {},
   "source": [
    "### Downloading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32962626",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = \"./datasets/raw/meta-California.json.gz\"\n",
    "meta_keys = [\"gmap_id\", \"name\", \"latitude\", \"longitude\", \"category\", \"avg_rating\", \"num_of_reviews\", \"price\", \"hours\"]\n",
    "\n",
    "review_path = \"./datasets/raw/review-California.json.gz\"\n",
    "review_keys = [\"gmap_id\", \"user_id\", \"name\", \"time\", \"rating\"]\n",
    "\n",
    "total_reviews = 70529977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a18f7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_meta_data():\n",
    "    url = \"https://mcauleylab.ucsd.edu/public_datasets/gdrive/googlelocal/meta-California.json.gz\"\n",
    "    res = requests.get(url, stream=True)\n",
    "\n",
    "    with open(meta_path, \"wb\") as f:\n",
    "        f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7294699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_review_data():\n",
    "    url = \"https://mcauleylab.ucsd.edu/public_datasets/gdrive/googlelocal/review-California.json.gz\"\n",
    "    res = requests.get(url, stream=True)\n",
    "\n",
    "    with open(review_path, \"wb\") as f:\n",
    "        f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06ffd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./datasets/raw\", exist_ok=True)\n",
    "os.makedirs(\"./datasets/processed\", exist_ok=True)\n",
    "\n",
    "if not os.path.exists(meta_path):\n",
    "    download_meta_data()\n",
    "\n",
    "if not os.path.exists(\"./datasets/raw/review-California.json.gz\"):\n",
    "    download_review_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad61ce8",
   "metadata": {},
   "source": [
    "### Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb43ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, \"r\")\n",
    "    for l in g:\n",
    "        yield json.loads(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8214245",
   "metadata": {},
   "source": [
    "Processing business data to extract Cafes we want to focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6829fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I reused my code from COGS108 project to process dataset.\n",
    "\n",
    "def get_cafe_categories():\n",
    "    categories = []\n",
    "    for business in parse(meta_path):\n",
    "        if business[\"category\"] is not None:\n",
    "            categories += business[\"category\"]\n",
    "\n",
    "    categories = np.array(categories)\n",
    "    unique = np.unique(categories)\n",
    "\n",
    "    cafe_categories = [str(category) for category in unique if \"cafe\" in category.lower() or \"coffee\" in category.lower()]\n",
    "    print(f\"The number of categories containting 'cafe' substring is {len(cafe_categories)}\")\n",
    "    print(cafe_categories)\n",
    "\n",
    "    with open(f\"./datasets/processed/cafe_categories.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(cafe_categories))\n",
    "\n",
    "def filter_by_category(data, categories):\n",
    "    category = data.get(\"category\", None)\n",
    "    if category is None:\n",
    "        return False\n",
    "\n",
    "    return len(set(category) & categories) != 0\n",
    "\n",
    "def filter_by_num_reviews(data, min_num_reviews):\n",
    "    return data[\"num_of_reviews\"] >= min_num_reviews\n",
    "\n",
    "def filter_raw_business_data(filters):\n",
    "    businesses = []\n",
    "    for business in parse(meta_path):\n",
    "        if all([f(data=business) for f in filters]):\n",
    "            business = {key: business.get(key, None) for key in meta_keys}\n",
    "            businesses.append(business)\n",
    "\n",
    "    print(f\"We obtained total of {len(businesses)} after filtering\")\n",
    "\n",
    "    df = pd.DataFrame(businesses)\n",
    "    df.to_csv(f\"./datasets/processed/cafes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "580be6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./datasets/processed/cafe_categories.txt\"):\n",
    "        get_cafe_categories()\n",
    "\n",
    "if not os.path.exists(\"./datasets/processed/cafes.csv\"):\n",
    "    min_num_reviews = 100\n",
    "\n",
    "    with open(\"./datasets/processed/cafe_categories.txt\", \"r\") as f:\n",
    "        cafe_categories = set(f.read().split(\"\\n\"))\n",
    "\n",
    "    cafe_filter = partial(filter_by_category, categories=cafe_categories)\n",
    "    num_reviews_filter = partial(filter_by_num_reviews, min_num_reviews=min_num_reviews)\n",
    "\n",
    "    filter_raw_business_data([cafe_filter, num_reviews_filter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850feefc",
   "metadata": {},
   "source": [
    "Processing review data to extract reviews we want to focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2eb99b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I reused my code from COGS108 project to process dataset.\n",
    "\n",
    "def filter_by_gmap_id(data, gmap_ids):\n",
    "    gmap_id = data.get(\"gmap_id\", None)\n",
    "    if gmap_id is None:\n",
    "        return False\n",
    "\n",
    "    return gmap_id in gmap_ids\n",
    "\n",
    "def filter_raw_review_data(filters):\n",
    "    reviews = []\n",
    "\n",
    "    for review in tqdm.tqdm(parse(review_path), total=total_reviews):\n",
    "        if all([f(data=review) for f in filters]):\n",
    "            review = {key: review.get(key, None) for key in review_keys}\n",
    "            review[\"review_id\"] = f\"{review['user_id']}_{review['gmap_id']}\"\n",
    "            reviews.append(review)\n",
    "\n",
    "    print(f\"We obtained total of {len(reviews)} after filtering\")\n",
    "    df = pd.DataFrame(reviews)\n",
    "    df.to_csv(\"./datasets/raw/cafe_reviews.csv\", index=False)\n",
    "\n",
    "def extract_user_ids(reviews, min_num_reviews):\n",
    "    user_ids = reviews[\"user_id\"].dropna().values\n",
    "    unique, counts = np.unique(np.array(user_ids), return_counts=True)\n",
    "    users = pd.DataFrame({\"user_id\": unique, \"num_reviews\": counts})\n",
    "\n",
    "    users = users[users[\"num_reviews\"] >= min_num_reviews].reset_index(drop=True)\n",
    "    print(f\"We extracted {users.shape[0]} users after filtering.\")\n",
    "\n",
    "    users.to_csv(\"./datasets/processed/users.csv\", index=False)\n",
    "\n",
    "def filter_by_user_ids(reviews, user_ids):\n",
    "    reviews = reviews[reviews[\"user_id\"].isin(user_ids)]\n",
    "\n",
    "    print(f\"We extracted {reviews.shape[0]} reviews after filtering.\")\n",
    "    reviews.to_csv(\"./datasets/processed/reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "89381faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./datasets/raw/cafe_reviews.csv\"):\n",
    "    gmap_ids = set(pd.read_csv(\"./datasets/processed/cafes.csv\")[\"gmap_id\"].values)\n",
    "    gmap_id_filter = partial(filter_by_gmap_id, gmap_ids=gmap_ids)\n",
    "    filter_raw_review_data([gmap_id_filter])\n",
    "\n",
    "if not os.path.exists(\"./datasets/processed/users.csv\"):\n",
    "    print(\"Start processing user data\")\n",
    "    reviews = pd.read_csv(\"./datasets/raw/cafe_reviews.csv\")\n",
    "    min_num_reviews = 20\n",
    "    extract_user_ids(reviews, min_num_reviews)\n",
    "\n",
    "if not os.path.exists(\"./datasets/processed/reviews.csv\"):\n",
    "    print(\"Start filtering review data\")\n",
    "    reviews = pd.read_csv(\"./datasets/raw/cafe_reviews.csv\")\n",
    "    user_ids = pd.read_csv(\"./datasets/processed/users.csv\")[\"user_id\"].values\n",
    "    filter_by_user_ids(reviews, user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f879f6",
   "metadata": {},
   "source": [
    "Split dataset into train, validation, and test so that we can evaluate models with unseen data. However, due to the design of the model which relies on pre-defined list of user and cafes, we need to split randomly without stratifying based on users or cafes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e5b56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_reviews():\n",
    "    file_name = \"./datasets/processed/reviews.csv\"\n",
    "    reviews = pd.read_csv(file_name).sample(frac=1, random_state=42)\n",
    "\n",
    "    valid_size = int(reviews.shape[0] * 0.1)\n",
    "    test_size = int(reviews.shape[0] * 0.1)\n",
    "\n",
    "    valid_reviews = reviews.iloc[:valid_size].reset_index(drop=True)\n",
    "    test_reviews = reviews.iloc[valid_size: valid_size + test_size].reset_index(drop=True)\n",
    "    train_reviews = reviews.iloc[valid_size + test_size:].reset_index(drop=True)\n",
    "\n",
    "    print(f\"train: {train_reviews.shape[0]} / valid: {valid_reviews.shape[0]} / test: {test_reviews.shape[0]}\")\n",
    "\n",
    "    os.makedirs(\"./datasets/splits\", exist_ok=True)\n",
    "\n",
    "    train_reviews.to_csv(\"./datasets/splits/train.csv\", index=False)\n",
    "    valid_reviews.to_csv(\"./datasets/splits/valid.csv\", index=False)\n",
    "    test_reviews.to_csv(\"./datasets/splits/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "340db926",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./datasets/splits/train.csv\"):\n",
    "    split_reviews()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c40b58",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0e9bef",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f8804",
   "metadata": {},
   "source": [
    "### Review Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82657392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding for Unix Time Weekday\n",
    "def unix_weekday_to_onehot(time):\n",
    "    feature_weekday = [0]*7\n",
    "\n",
    "    day = datetime.fromtimestamp(time / 1000, tz=timezone.utc).weekday()\n",
    "    feature_weekday[day] = 1.\n",
    "\n",
    "    return feature_weekday\n",
    "\n",
    "# One Hot Encoding for Unix Time Hour\n",
    "def unix_hour_to_onehot(time):\n",
    "    feature_dayhour = [0]*24\n",
    "\n",
    "    hr = datetime.fromtimestamp(time / 1000, tz=timezone.utc).hour\n",
    "    feature_dayhour[hr] = 1.\n",
    "\n",
    "    return feature_dayhour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd3343f",
   "metadata": {},
   "source": [
    "### Review Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "519bf502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding for Period\n",
    "def unix_period_to_onehot(unix_ms):\n",
    "    \"\"\"\n",
    "      0 -> before 2016\n",
    "      1 -> 2016-2019\n",
    "      2 -> 2020 and later\n",
    "    \"\"\"\n",
    "    if pd.isna(unix_ms):\n",
    "        return np.nan\n",
    "    try:\n",
    "        t = int(unix_ms)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "    b2016_ms = int(pd.Timestamp(\"2016-01-01\").timestamp() * 1000)\n",
    "    b2020_ms = int(pd.Timestamp(\"2020-01-01\").timestamp() * 1000)\n",
    "\n",
    "    if t < b2016_ms:\n",
    "        return [0, 0, 0]\n",
    "    elif t < b2020_ms:\n",
    "        return [0, 1., 0]\n",
    "    else:\n",
    "        return [0, 0, 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e7ee0",
   "metadata": {},
   "source": [
    "### Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f12438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chains_dict(cafes):\n",
    "    names, counts = np.unique(cafes[\"name\"], return_counts=True)\n",
    "    indices = np.argsort(counts)[::-1]\n",
    "    sorted_counts = counts[indices]\n",
    "    sorted_names = names[indices]\n",
    "\n",
    "    stems = defaultdict(int)\n",
    "    for name in sorted_names:\n",
    "        words = name.lower().strip().split()\n",
    "\n",
    "        for i in range(len(words)):\n",
    "            stems[\" \".join(words[:(i+1)])] += 1\n",
    "\n",
    "    chains = {}\n",
    "    for name, count in zip(sorted_names, sorted_counts):\n",
    "        if count > 5:\n",
    "            chains[name] = 2\n",
    "            continue\n",
    "\n",
    "        words = name.lower().strip().split()\n",
    "        stem_matches = []\n",
    "        for i in range(len(words)):\n",
    "            stem_matches.append(stems[\" \".join(words[:(i+1)])])\n",
    "\n",
    "        if len(stem_matches) == 1 or len(stem_matches) > 10:\n",
    "            chains[name] = 0\n",
    "            continue\n",
    "\n",
    "        if len(stem_matches) >= 2 and sum(stem_matches[1:]) < 10:\n",
    "            chains[name] = 0\n",
    "            continue\n",
    "\n",
    "        if len(stem_matches) >= 3 and sum(stem_matches[2:]) < 5:\n",
    "            chains[name] = 0\n",
    "            continue\n",
    "\n",
    "        chains[name] = 1\n",
    "\n",
    "    return chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35364511",
   "metadata": {},
   "source": [
    "### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e6097e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding for Price\n",
    "def price_to_onehot(price):\n",
    "    feature_price = [0]*4\n",
    "    if price is not np.nan:\n",
    "        feature_price[len(price)-1] += 1.\n",
    "    return feature_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1d859",
   "metadata": {},
   "source": [
    "### Open Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff592250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts time text to values\n",
    "def parse_time(t):\n",
    "    t = t.strip().upper()\n",
    "\n",
    "    # Match hh or hh:mm formats\n",
    "    m = re.match(r\"(\\d{1,2})(?::(\\d{2}))?(AM|PM)\", t)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Invalid time format: {t}\")\n",
    "\n",
    "    hour = int(m.group(1))\n",
    "    minute = int(m.group(2) or 0)\n",
    "    period = m.group(3)\n",
    "\n",
    "    # Convert to 24-hour\n",
    "    if period == \"AM\":\n",
    "        if hour == 12:\n",
    "            hour = 0\n",
    "    else:  # PM\n",
    "        if hour != 12:\n",
    "            hour += 12\n",
    "\n",
    "    return hour + minute / 60.0\n",
    "\n",
    "# One Hot Encoding for Open Hours\n",
    "def hours_to_onehot(hour_str):\n",
    "    if hour_str is None or hour_str is np.nan:\n",
    "        return [0,0,0]\n",
    "    before_noon = 0\n",
    "    after_noon = 0\n",
    "    hours = ast.literal_eval(hour_str)\n",
    "\n",
    "    for entry in hours:\n",
    "        if entry[1] == \"Open 24 hours\":\n",
    "            return [1.,0,0]\n",
    "        if entry[1] == \"Closed\":\n",
    "            continue\n",
    "\n",
    "        open_str, close_str = entry[1].split(\"â€“\")\n",
    "        try:\n",
    "            start_hr = int(np.floor(parse_time(open_str)))\n",
    "        except ValueError:\n",
    "            return [0,0,0]\n",
    "        if start_hr < 13:\n",
    "            before_noon += 1.\n",
    "        else: after_noon += 1.\n",
    "\n",
    "    if before_noon > after_noon:\n",
    "        return [0,1.,0]\n",
    "    return [0,0,1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d78d2",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7211ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def get_counties_ca():\n",
    "    counties = gpd.read_file(\"resources/cb_2018_us_county_500k.shp\")\n",
    "    counties_ca = counties[counties[\"STATEFP\"] == \"06\"]  # California only\n",
    "    counties_ca = counties_ca.sort_values(\"NAME\").reset_index(drop=True)\n",
    "    counties_ca[\"COUNTY_NUM\"] = counties_ca.index\n",
    "    counties_ca = counties_ca.set_geometry(\"geometry\")\n",
    "    _ = counties_ca.sindex\n",
    "    return counties_ca\n",
    "\n",
    "def get_county(lat, lon):\n",
    "    counties_ca = get_counties_ca()\n",
    "    point = Point(lon, lat)  # geometry expects (lon, lat)\n",
    "    idx = list(counties_ca.sindex.intersection(point.bounds))\n",
    "    if not idx:\n",
    "        return None\n",
    "    candidates = counties_ca.iloc[idx]\n",
    "    matches = candidates[candidates.contains(point)]\n",
    "    return int(matches.iloc[0][\"COUNTY_NUM\"]) if len(matches) else None\n",
    "\n",
    "def location_to_onehot(location):\n",
    "    feature_county =[0]*58  # 58 counties in Cali\n",
    "\n",
    "    if location is not None:\n",
    "        feature_county[location] = 1.\n",
    "\n",
    "    return feature_county"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cdc429",
   "metadata": {},
   "source": [
    "### User History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4943c9",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee087cc",
   "metadata": {},
   "source": [
    "### Feature Matrix Consturction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2e889",
   "metadata": {},
   "source": [
    "We construct dictionaries converting the following:\n",
    "- `user_id` to index of onehot vector for user.\n",
    "- `gmap_id` to index of onehot vector for cafe.\n",
    "- `price` to onehot vector for cafe price.\n",
    "- `hours` to onehot vector for whether a cafe is open all day, morning, or evening.\n",
    "- `latitude` and `longitude` to index of onehot vector for counties in California.\n",
    "- `chains` to onehot vector for size of chain (none, small, large).\n",
    "- `prev` to index of onehot vector for cafe that user previously rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3478ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_latent(feat_names):\n",
    "    reviews = pd.read_csv(\"./datasets/processed/reviews.csv\")\n",
    "    cafes = pd.read_csv(\"./datasets/processed/cafes.csv\")\n",
    "\n",
    "    feat_dicts = {}\n",
    "    for name in feat_names:\n",
    "        if name == \"user\":\n",
    "            unique_user_ids = np.sort(np.unique(reviews[\"user_id\"].values))\n",
    "            user2index = {user_id: index for index, user_id in enumerate(unique_user_ids)}\n",
    "            feat_dicts[name] = user2index\n",
    "\n",
    "        elif name == \"cafe\":\n",
    "            unique_gmap_ids = np.sort(np.unique(cafes[\"gmap_id\"]))\n",
    "            cafe2index = {gmap_id: index for index, gmap_id in enumerate(unique_gmap_ids)}\n",
    "            feat_dicts[name] = cafe2index\n",
    "\n",
    "        elif name == \"price\":\n",
    "            unique_gmap_ids, indices = np.unique(cafes[\"gmap_id\"], return_index=True)\n",
    "            order = np.argsort(unique_gmap_ids)\n",
    "            unique_gmap_ids = unique_gmap_ids[order]\n",
    "            indices = indices[order]\n",
    "            cafe2price = {gmap_id: cafes[\"price\"][index] for gmap_id, index in zip(unique_gmap_ids, indices)}\n",
    "            feat_dicts[name] = cafe2price\n",
    "\n",
    "        elif name == \"open_hours\":\n",
    "            unique_gmap_ids, indices = np.unique(cafes[\"gmap_id\"], return_index=True)\n",
    "            order = np.argsort(unique_gmap_ids)\n",
    "            unique_gmap_ids = unique_gmap_ids[order]\n",
    "            indices = indices[order]\n",
    "            cafe2hours = {gmap_id: cafes[\"hours\"][index] for gmap_id, index in zip(unique_gmap_ids, indices)}\n",
    "            feat_dicts[name] = cafe2hours\n",
    "\n",
    "        elif name == \"location\":\n",
    "            unique_gmap_ids, indices = np.unique(cafes[\"gmap_id\"], return_index=True)\n",
    "            order = np.argsort(unique_gmap_ids)\n",
    "            unique_gmap_ids = unique_gmap_ids[order]\n",
    "            indices = indices[order]\n",
    "            cafe2location = {gmap_id: get_county(cafes[\"latitude\"][index],cafes[\"longitude\"][index]) for gmap_id, index in zip(unique_gmap_ids, indices)}\n",
    "            feat_dicts[name] = cafe2location\n",
    "\n",
    "        elif name == \"chains\":\n",
    "            unique_gmap_ids, indices = np.unique(cafes[\"gmap_id\"], return_index=True)\n",
    "            order = np.argsort(unique_gmap_ids)\n",
    "            unique_gmap_ids = unique_gmap_ids[order]\n",
    "            indices = indices[order]\n",
    "\n",
    "            chains = get_chains_dict(cafes)\n",
    "            cafe2chain = {gmap_id: chains[cafes[\"name\"][index]] for gmap_id, index in zip(unique_gmap_ids, indices)}\n",
    "            feat_dicts[name] = cafe2chain\n",
    "\n",
    "        elif name == \"prev\":\n",
    "            reviews_sorted = reviews.sort_values(by=['user_id', 'time'])\n",
    "\n",
    "            user_interactions = (\n",
    "                reviews_sorted.groupby('user_id')['gmap_id']\n",
    "                .apply(list)\n",
    "                .to_dict()\n",
    "            )\n",
    "\n",
    "            feat_dicts[name] = user_interactions\n",
    "\n",
    "    avg_rating = reviews[\"rating\"].mean()\n",
    "\n",
    "    return feat_dicts, avg_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dfe59d",
   "metadata": {},
   "source": [
    "Then, we construct PyTorch Dataset. This class is desgined to be flexible about which features that are used. It receives a list of feature names in `feat_names` that will be used in the model and uses `feat_dicts` to map data to onehot vector. The following features that can be used are:\n",
    "- `alpha` is a bias term and we initialize it with global average of rating.\n",
    "- `user` is a user of a review.\n",
    "- `cafe` is a cafe of a review.\n",
    "- `weekday` is a weekday of a week when a review was posted.\n",
    "- `hour` is an hour of a day when a review was posted.\n",
    "- `price` is the price of the cafe (listed as either $, $$, $$$, or $$$$).\n",
    "- `open_hours` is the open hours of the cafe.\n",
    "- `location` is the location (county) of the cafe.\n",
    "- `chains` is whether a cafe is a large or small chain - or not a chain at all.\n",
    "- `prev` is the previous cafe the user review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "80f558a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CafeDatasetLatent(Dataset):\n",
    "    def __init__(self, mode, feat_names, feat_dicts):\n",
    "        self.reviews = pd.read_csv(f\"./datasets/splits/{mode}.csv\").values\n",
    "\n",
    "        self.feat_names = feat_names\n",
    "        self.feat_dicts = feat_dicts\n",
    "\n",
    "    def get_feat_sizes(self):\n",
    "        feat_sizes = {}\n",
    "\n",
    "        for name in self.feat_names:\n",
    "            if name == \"alpha\":\n",
    "                feat_sizes[name] = 1\n",
    "\n",
    "            elif name == \"user\":\n",
    "                feat_sizes[name] = len(self.feat_dicts[name].keys())\n",
    "\n",
    "            elif name == \"cafe\":\n",
    "                feat_sizes[name] = len(self.feat_dicts[name].keys())\n",
    "\n",
    "            elif name == \"weekday\":\n",
    "                feat_sizes[name] = 7\n",
    "\n",
    "            elif name == \"hour\":\n",
    "                feat_sizes[name] = 24\n",
    "\n",
    "            elif name == \"price\":\n",
    "                feat_sizes[name] = 4\n",
    "\n",
    "            elif name == \"open_hours\":\n",
    "                feat_sizes[name] = 3\n",
    "\n",
    "            elif name == \"location\":\n",
    "                feat_sizes[name] = 58\n",
    "\n",
    "            elif name == \"chains\":\n",
    "                feat_sizes[name] = 3\n",
    "\n",
    "            elif name == \"period\":\n",
    "                feat_sizes[name] = 3\n",
    "\n",
    "            elif name == \"prev\":\n",
    "                feat_sizes[name] = len(self.feat_dicts[\"cafe\"].keys())\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        return feat_sizes\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.reviews.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        review = self.reviews[index]\n",
    "        feats = []\n",
    "        for name in self.feat_names:\n",
    "            if name == \"alpha\":\n",
    "                feat = torch.ones(1)\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"user\":\n",
    "                feat_dict = self.feat_dicts[name]\n",
    "                feat = torch.zeros(len(feat_dict.keys()))\n",
    "                feat[feat_dict[review[1]]] = 1.\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"cafe\":\n",
    "                feat_dict = self.feat_dicts[name]\n",
    "                feat = torch.zeros(len(feat_dict.keys()))\n",
    "                feat[feat_dict[review[0]]] = 1.\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"weekday\":\n",
    "                feat = torch.tensor(unix_weekday_to_onehot(int(review[3])))\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"hour\":\n",
    "                feat = torch.tensor(unix_hour_to_onehot(int(review[3])))\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"price\":\n",
    "                feat_dict = self.feat_dicts[name]\n",
    "                feat = torch.tensor(price_to_onehot(feat_dict[review[0]]))\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"open_hours\":\n",
    "                feat_dict = self.feat_dicts[name]\n",
    "                feat = torch.tensor(hours_to_onehot(feat_dict[review[0]]))\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"location\":\n",
    "                feat_dict = self.feat_dicts[name]\n",
    "                feat = torch.tensor(location_to_onehot(feat_dict[review[0]]))\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"chains\":\n",
    "                feat_dict = self.feat_dicts[name]\n",
    "                feat = torch.zeros(3)\n",
    "                feat[feat_dict[review[0]]] = 1.\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"period\":\n",
    "                feat = torch.tensor(unix_period_to_onehot(int(review[3])))\n",
    "                feats.append(feat)\n",
    "\n",
    "            elif name == \"prev\":\n",
    "                cafe_feat_dict = self.feat_dicts['cafe']    # All cafes\n",
    "                feat_dict = self.feat_dicts[name]           # List of user -> list of all cafes user rated\n",
    "                feat = torch.zeros(len(cafe_feat_dict.keys()))\n",
    "                user = review[1]\n",
    "                current_item = review[0]\n",
    "                i = feat_dict[user].index(current_item)     # Get index of current cafe in user list\n",
    "                if i > 0:\n",
    "                    prev_item = feat_dict[user][i-1]\n",
    "                    feat[cafe_feat_dict[prev_item]] = 1.\n",
    "                feats.append(feat)\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        rating = torch.tensor(review[4])\n",
    "\n",
    "        return *feats, rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ca7f2",
   "metadata": {},
   "source": [
    "Next, we construct a model for rating prediction. This class is also designed to be flexible and it receives following arguments:\n",
    "- `name` is a unique identifier of a model.\n",
    "- `dim` is a dimension of latent.\n",
    "- `feat_sizes` is a list of feature sizes which would be used to initialize weights.\n",
    "- `latent_names` is a list of latent feature names which would be used to initialize latents.\n",
    "- `latent_pairs` is a list of tuples which indicate pairs we would calculate dot product in between.\n",
    "- `avg_rating` is a global average rating which is used to initialize alpha.\n",
    "- `share_latents` is indicator used for user history model to share latents for current and previous cafes. \n",
    "  \n",
    "This model has two sets of parameters:\n",
    "- `weights` is a dictionary of weights for each feature and corresponds to betas in model equation.\n",
    "- `latents` is a dictionary of latents for feature we specified and corresponds to gammas in model equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6535a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatePredictorLatent(nn.Module):\n",
    "    def __init__(self, name, dim, feat_sizes, latent_names, latent_pairs, avg_rating, share_latents=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.name = name\n",
    "\n",
    "        self.feat_names = list(feat_sizes.keys())\n",
    "        self.latent_names = latent_names\n",
    "        self.latent_pairs = latent_pairs\n",
    "\n",
    "        self.share_latents = share_latents\n",
    "\n",
    "        weights = {}\n",
    "        for name, feat_size in feat_sizes.items():\n",
    "            if self.share_latents and name == \"prev\":\n",
    "                continue\n",
    "\n",
    "            if name == \"alpha\":\n",
    "                weight = torch.tensor(avg_rating).unsqueeze(0)\n",
    "            else:\n",
    "                weight = torch.zeros(feat_size)\n",
    "            weights[name] = nn.Parameter(weight, requires_grad=True)\n",
    "\n",
    "        self.weights =  nn.ParameterDict(weights)\n",
    "\n",
    "        latents = {}\n",
    "        for name in latent_names:\n",
    "            feat_size = feat_sizes[name]\n",
    "            latent = torch.randn(feat_size, dim) / dim\n",
    "            latents[name] = nn.Parameter(latent, requires_grad=True)\n",
    "\n",
    "        self.latents = nn.ParameterDict(latents)\n",
    "\n",
    "    def forward(self, feats):\n",
    "        out = torch.zeros(feats[\"alpha\"].size(0)).to(feats[\"alpha\"].device)\n",
    "        for name in self.feat_names:\n",
    "            if self.share_latents and name == \"prev\":\n",
    "                continue\n",
    "\n",
    "            out += torch.einsum(\"bd,d->b\", feats[name], self.weights[name])\n",
    "\n",
    "        gammas = {}\n",
    "        for name in self.latent_names:\n",
    "            gammas[name] = torch.einsum(\"bd,di->bi\", feats[name], self.latents[name])\n",
    "\n",
    "        if self.share_latents:\n",
    "            gammas[\"prev\"] = torch.einsum(\"bd,di->bi\", feats[\"prev\"], self.latents[\"cafe\"])\n",
    "\n",
    "        for (latent_i, latent_j) in self.latent_pairs:\n",
    "            out += torch.einsum(\"bi,bi->b\", gammas[latent_i], gammas[latent_j])\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97863d7",
   "metadata": {},
   "source": [
    "Next, we construct a trainer to train a model by using autograd of PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "73789ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateTrainerLatent():\n",
    "    def __init__(self, model, lamb_dict, lr, train_dataloader, valid_dataloader, device):\n",
    "        self.model = model\n",
    "        self.lamb_dict = lamb_dict\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.device = device\n",
    "\n",
    "        self.feat_names = model.feat_names\n",
    "        self.latent_names = model.latent_names\n",
    "\n",
    "        self.optim =  torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "        train_mses, valid_mses = [], []\n",
    "        best_mse = float(\"inf\")\n",
    "        for i in range(n_epochs):\n",
    "            train_mse = 0\n",
    "            total = 0\n",
    "\n",
    "            bar = tqdm.tqdm(self.train_dataloader, desc=\"Training Model\")\n",
    "            for feats in bar:\n",
    "                ratings = feats[-1].to(self.device)\n",
    "                assert len(self.feat_names) + 1 == len(feats)\n",
    "                feats = {name: f.to(self.device) for name, f in zip(self.feat_names, feats[:-1])}\n",
    "\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "                pred_ratings = self.model(feats)\n",
    "                mse = self.mse(ratings, pred_ratings)\n",
    "                mse_reg = mse + self.regularizer()\n",
    "\n",
    "                mse_reg.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "                batch_size = feats[\"alpha\"].size(0)\n",
    "                train_mse += mse.item() * batch_size\n",
    "                total += batch_size\n",
    "\n",
    "                bar.set_description(f\"Training Model ({mse.item():.6f})\")\n",
    "\n",
    "            train_mse /= total\n",
    "            valid_mse = self.validate()\n",
    "            print(f\"Step[{i + 1:2d}]: train {train_mse:2.6f} / valid {valid_mse:2.6f}\")\n",
    "\n",
    "            if valid_mse < best_mse:\n",
    "                best_mse = valid_mse\n",
    "                torch.save(self.model, f\"./models/{self.model.name}.pt\")\n",
    "\n",
    "            train_mses.append(train_mse)\n",
    "            valid_mses.append(valid_mse)\n",
    "\n",
    "        return train_mses, valid_mses\n",
    "\n",
    "    def validate(self):\n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            mse = 0\n",
    "\n",
    "            for feats in self.valid_dataloader:\n",
    "                ratings = feats[-1].to(self.device)\n",
    "                assert len(self.feat_names) + 1 == len(feats)\n",
    "                feats = {name: f.to(self.device) for name, f in zip(self.feat_names, feats[:-1])}\n",
    "\n",
    "                pred_ratings = self.model(feats)\n",
    "\n",
    "                batch_size = feats[\"alpha\"].size(0)\n",
    "                mse += self.mse(ratings, pred_ratings).item() * batch_size\n",
    "                total += batch_size\n",
    "\n",
    "            return mse / total\n",
    "\n",
    "    def mse(self, y_true, y_pred):\n",
    "        return torch.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "    def regularizer(self):\n",
    "        reg = 0\n",
    "        for name in self.feat_names:\n",
    "            if self.model.share_latents and name == \"prev\":\n",
    "                continue\n",
    "\n",
    "            reg += self.lamb_dict[name] * torch.mean(self.model.weights[name] ** 2)\n",
    "\n",
    "        for name in self.latent_names:\n",
    "            latents = self.model.latents[name]\n",
    "            reg += self.lamb_dict[name] * latents.size(1) * torch.mean(latents ** 2)\n",
    "\n",
    "        return reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56da837",
   "metadata": {},
   "source": [
    "We record metrics in a file `metrics.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9427ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metrics(name, train, valid):\n",
    "    if os.path.exists(\"./metrics.json\"):\n",
    "        with open(\"./metrics.json\", \"r\") as f:\n",
    "           metrics = json.load(f)\n",
    "    else:\n",
    "        metrics = {}\n",
    "\n",
    "    metrics[name] = {\"metrics\": {\"train\": train, \"valid\": valid}}\n",
    "\n",
    "    with open(\"./metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4f1fc",
   "metadata": {},
   "source": [
    "After a series of experiments, we ended up using the following hyperparamters for all the experiments below:\n",
    "- `n_epoch` is the numer of iterations for training.\n",
    "- `lr` is a learning rate of gradient descent.\n",
    "- `dim` is a dimension of latents if used.\n",
    "- `batch_size` is a batch size of training.\n",
    "- `device` is a device we run models on. You can change \"cpu\" to \"cuda\" if you have GPU environment. However, we only tested on \"cpu\" so we cannot guarantee that it would work on \"gpu\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fcab1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "lr = 0.01\n",
    "dim = 32\n",
    "batch_size = 2048\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d88d37",
   "metadata": {},
   "source": [
    "Then we define `train` function which train a model given a parameter dictionary called `param_dict` which requires the following keys:\n",
    "- `feat` is a category of a model where we used \"base\", \"chains\", \"price\", \"open_hours\", \"time\", \"period\", and \"prev\". We add \"_latent\" if it uses latents.\n",
    "- `feat_names` is a list of features that model uses.\n",
    "- `latent_names` is a list of features that model computes latents for.\n",
    "- `latent_pairs` is a list of pairs of latent features which model computs dot product for.\n",
    "- `lamb_dict` is a dictionary which maps feature name to regularizer coefficient for each feature.\n",
    "- `share_latents` is a indicator if model share latents for current and previous cafe in user history model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "38cb49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(param_dict):\n",
    "    feat = param_dict[\"feat\"]\n",
    "    feat_names = param_dict[\"feat_names\"]\n",
    "    latent_names = param_dict[\"latent_names\"]\n",
    "    latent_pairs = param_dict[\"latent_pairs\"]\n",
    "    lamb_dict = param_dict[\"lamb_dict\"]\n",
    "    share_latents = param_dict.get(\"share_latents\", 0)\n",
    "\n",
    "    lamb_str = \"_\".join([f\"{name}-{value}\" for name, value in lamb_dict.items()])\n",
    "    name = f\"{feat}_{lamb_str}\"\n",
    "\n",
    "    if not os.path.exists(f\"./models/{name}.pt\"):\n",
    "        print(f\"Start training {name}\")\n",
    "\n",
    "        feat_dicts, avg_rating = preprocess_data_latent(feat_names)\n",
    "        train_dataset = CafeDatasetLatent(\"train\", feat_names, feat_dicts)\n",
    "        valid_dataset = CafeDatasetLatent(\"valid\", feat_names, feat_dicts)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        feat_sizes = train_dataset.get_feat_sizes()\n",
    "        model = RatePredictorLatent(name, dim, feat_sizes, latent_names, latent_pairs, avg_rating, share_latents=share_latents)\n",
    "\n",
    "        trainer = RateTrainerLatent(model, lamb_dict, lr, train_dataloader, valid_dataloader, device)\n",
    "\n",
    "        os.makedirs(\"./models\", exist_ok=True)\n",
    "        train_mses, valid_mses = trainer.train(n_epoch)\n",
    "\n",
    "        update_metrics(name, train_mses, valid_mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf44042",
   "metadata": {},
   "source": [
    "### Plotting Results\n",
    "We plot results to compare performance on validation set and see training history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badaecad",
   "metadata": {},
   "source": [
    "## Running Models to Find Hyper-Parameters\n",
    "\n",
    "In the following sections, we train models to test if adding specific feature would boost performance and which regularizer coefficient is best for each feature. This would take hours to run so this code won't run training. However, if you want to run training you can set a variable `validation` as `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c254d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be06bc42",
   "metadata": {},
   "source": [
    "### Base without Latents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a1aa0",
   "metadata": {},
   "source": [
    "We train a naive model where we only use features of `user_id` and `cafe` without latents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "15f4967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"base\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\"],\n",
    "        \"latent_names\": [],\n",
    "        \"latent_pairs\": [],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1},\n",
    "        \"test\": 1\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"base\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\"],\n",
    "        \"latent_names\": [],\n",
    "        \"latent_pairs\": [],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 1, \"cafe\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"base\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\"],\n",
    "        \"latent_names\": [],\n",
    "        \"latent_pairs\": [],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"base\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\"],\n",
    "        \"latent_names\": [],\n",
    "        \"latent_pairs\": [],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 1, \"cafe\": 1},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b1433d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161108ee",
   "metadata": {},
   "source": [
    "### Base with Latents (User x Cafe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594c6c1",
   "metadata": {},
   "source": [
    "Next, we train a naive model with latents for `user` and `cafe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f4331ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"base_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1},\n",
    "        \"test\": 1\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"base_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 1, \"cafe\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"base_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"base_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 1, \"cafe\": 1},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1482cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e635e8c",
   "metadata": {},
   "source": [
    "### Review Time without Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb7ca7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"time\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"weekday\": 1, \"hour\": 1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"time\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"weekday\": 0.1, \"hour\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"time\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"weekday\": 0.01, \"hour\": 0.01},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cea39deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb26aa19",
   "metadata": {},
   "source": [
    "### Review Time with Latents (User x Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "53ee00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"time_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"weekday\"], [\"user\", \"hour\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"weekday\": 1, \"hour\": 1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"time_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"weekday\"], [\"user\", \"hour\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"weekday\": 0.1, \"hour\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"time_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"weekday\"], [\"user\", \"hour\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"weekday\": 0.01, \"hour\": 0.01},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5e8c17d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ae7da",
   "metadata": {},
   "source": [
    "### Review Time with Latents (User x Time and Cafe x Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0477e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"time_all_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"weekday\"], [\"user\", \"hour\"], [\"cafe\", \"weekday\"], [\"cafe\", \"hour\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"weekday\": 1, \"hour\": 1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"time_all_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"weekday\"], [\"user\", \"hour\"], [\"cafe\", \"weekday\"], [\"cafe\", \"hour\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"weekday\": 0.1, \"hour\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"time_all_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"weekday\", \"hour\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"weekday\"], [\"user\", \"hour\"], [\"cafe\", \"weekday\"], [\"cafe\", \"hour\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"weekday\": 0.01, \"hour\": 0.01},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "499b37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3465d",
   "metadata": {},
   "source": [
    "### Review Period without Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2cfcf6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"period\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"period\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"period\": 0.01},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"period\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"period\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"period\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"period\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"period\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"period\": 1},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dfe32860",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab854a0",
   "metadata": {},
   "source": [
    "### Review Period with Latents (User x Period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9823450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"period_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"period\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"period\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"period\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"period\": 0.01},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"period_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"period\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"period\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"period\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"period\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"period_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"period\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"period\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"period\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"period\": 1},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cb1f83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c4d6a",
   "metadata": {},
   "source": [
    "### Review Period with Latents (User x Period and Cafe x Period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64abec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"period_all_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"period\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"period\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"period\"], [\"cafe\", \"period\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"period\": 0.01},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"period_all_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"period\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"period\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"period\"], [\"cafe\", \"period\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"period\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"period_all_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"period\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"period\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"period\"], [\"cafe\", \"period\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"period\": 1},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5925a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6023e72",
   "metadata": {},
   "source": [
    "### Chains without Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "40d144fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"chains\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"chains\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"chains\": 0.01},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"chains\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"chains\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"chains\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"chains\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"chains\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"chains\": 1},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "13ead125",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e095a5a",
   "metadata": {},
   "source": [
    "### Chains with Latents (User x Chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c3f26bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"chains_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"chains\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"chains\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"chains\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"chains\": 0.01},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"chains_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"chains\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"chains\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"chains\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"chains\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"chains_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"chains\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"chains\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"chains\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"chains\": 1},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "28a72b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2f7bc",
   "metadata": {},
   "source": [
    "### Price without Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9c119ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"price\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"price\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"price\": 0.01},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"price\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"price\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"price\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"price\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"price\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"price\": 1},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8df15af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb3766",
   "metadata": {},
   "source": [
    "### Price with Latents (User x Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "95faf1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"price_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"price\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"price\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"price\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"price\": 0.01},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"price_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"price\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"price\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"price\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"price\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"price_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"price\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"price\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"price\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"price\": 1},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "702b1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ec898",
   "metadata": {},
   "source": [
    "### Open Hours without Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1818dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"open_hours\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"open_hours\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"open_hours\": 0.01},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"open_hours\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"open_hours\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"open_hours\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"open_hours\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"open_hours\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"open_hours\": 1},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d27a0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d72e73",
   "metadata": {},
   "source": [
    "### Open Hours with Latents (User x Open Hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bfc09f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"open_hours_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"open_hours\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"open_hours\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"open_hours\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"open_hours\": 0.01},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"open_hours_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"open_hours\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"open_hours\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"open_hours\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"open_hours\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"open_hours_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"open_hours\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"open_hours\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"open_hours\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"open_hours\": 1},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "54613b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363b1fe",
   "metadata": {},
   "source": [
    "### Location without Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ce6510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"location\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"location\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"location\": 1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"location\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"location\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"location\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"location\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"location\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"location\": 0.01},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "413edc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6c735",
   "metadata": {},
   "source": [
    "### Location with Latents (User x Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fce16187",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"location_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"location\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"location\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"location\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"location\": 1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"location_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"location\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"location\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"location\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"location\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"location_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"location\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"location\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"user\", \"location\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"location\": 0.01},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ad6426f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecbfadf",
   "metadata": {},
   "source": [
    "### Previous Cafe without Shared Latents (Cafe x Prev Cafe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "60bb9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"prev_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"prev\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"prev\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"cafe\", \"prev\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"prev\": 0.01},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"prev_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"prev\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"prev\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"cafe\", \"prev\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"prev\": 0.1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"prev_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"prev\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"prev\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"cafe\", \"prev\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"prev\": 1},\n",
    "        \"test\": 0\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"prev_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"prev\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\", \"prev\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"cafe\", \"prev\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1, \"prev\": 2},\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b0ed094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c764c30c",
   "metadata": {},
   "source": [
    "### Previous Cafe with Shared Latents (Cafe x Prev Cafe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9daacfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        \"feat\": \"prev_share_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"prev\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"], [\"cafe\", \"prev\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1},\n",
    "        \"share_latents\": 1,\n",
    "        \"test\": 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5baacde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation:\n",
    "    for param_dict in params:\n",
    "        train(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e2337",
   "metadata": {},
   "source": [
    "### Final Model\n",
    "Based on validation results above, we ended up building a model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f2dc0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_param_dict = {\n",
    "    \"feat\": \"final\",\n",
    "    \"feat_names\": [\"alpha\", \"user\", \"cafe\", \"chains\", \"price\", \"open_hours\", \"period\"],\n",
    "    \"latent_names\": [\"user\", \"cafe\", \"chains\", \"price\", \"open_hours\", \"period\"],\n",
    "    \"latent_pairs\": [\n",
    "        [\"user\", \"cafe\"],\n",
    "        [\"user\", \"chains\"],\n",
    "        [\"user\", \"price\"],\n",
    "        [\"user\", \"open_hours\"],\n",
    "        [\"user\", \"period\"],\n",
    "        [\"cafe\", \"period\"]\n",
    "    ],\n",
    "    \"lamb_dict\": {\n",
    "        \"alpha\": 0,\n",
    "        \"user\": 0.1,\n",
    "        \"cafe\": 1,\n",
    "        \"chains\": 0.1,\n",
    "        \"price\": 0.1,\n",
    "        \"open_hours\": 0.1,\n",
    "        \"period\": 0.1\n",
    "    },\n",
    "    \"test\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fb47ca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training final_alpha-0_user-0.1_cafe-1_chains-0.1_price-0.1_open_hours-0.1_period-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.687613): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:32<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 1]: train 0.773220 / valid 0.707462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.728353): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 2]: train 0.661663 / valid 0.696816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.684119): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 3]: train 0.633137 / valid 0.683982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.679846): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:32<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 4]: train 0.612937 / valid 0.677073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.632819): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 5]: train 0.598525 / valid 0.676221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.606009): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:30<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 6]: train 0.588929 / valid 0.672073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.607850): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:32<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 7]: train 0.580948 / valid 0.672967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.599912): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:32<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 8]: train 0.573513 / valid 0.673432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.527931): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:34<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 9]: train 0.566042 / valid 0.672014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.551830): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:33<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[10]: train 0.560062 / valid 0.668512\n"
     ]
    }
   ],
   "source": [
    "train(final_param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a83a8",
   "metadata": {},
   "source": [
    "### Baselines\n",
    "We need two baselines for further analysis and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5d7557ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_params = [\n",
    "    {\n",
    "        \"feat\": \"base\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\"],\n",
    "        \"latent_names\": [],\n",
    "        \"latent_pairs\": [],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1},\n",
    "        \"test\": 1\n",
    "    },\n",
    "    {\n",
    "        \"feat\": \"base_latent\",\n",
    "        \"feat_names\": [\"alpha\", \"user\", \"cafe\"],\n",
    "        \"latent_names\": [\"user\", \"cafe\"],\n",
    "        \"latent_pairs\": [[\"user\", \"cafe\"]],\n",
    "        \"lamb_dict\": {\"alpha\": 0, \"user\": 0.1, \"cafe\": 1},\n",
    "        \"test\": 1\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "38e7e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training base_alpha-0_user-0.1_cafe-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.797349): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:12<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 1]: train 0.908573 / valid 0.813373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.660651): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:12<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 2]: train 0.744445 / valid 0.742935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.709111): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:12<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 3]: train 0.686475 / valid 0.716396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.637560): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:12<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 4]: train 0.662078 / valid 0.705613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.670861): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:13<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 5]: train 0.650831 / valid 0.700571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.805753): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:13<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 6]: train 0.644343 / valid 0.698311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.724490): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:12<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 7]: train 0.641451 / valid 0.696828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.638892): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:12<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 8]: train 0.639362 / valid 0.695887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.620427): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:12<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 9]: train 0.638174 / valid 0.696224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.721040): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:12<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[10]: train 0.637649 / valid 0.695696\n",
      "Start training base_latent_alpha-0_user-0.1_cafe-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.789574): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:14<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 1]: train 0.906445 / valid 0.805249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.745804): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:14<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 2]: train 0.726233 / valid 0.727595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.686666): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:14<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 3]: train 0.663371 / valid 0.708040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.723429): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:14<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 4]: train 0.637929 / valid 0.698891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.655430): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:14<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 5]: train 0.621951 / valid 0.694273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.677528): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:14<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 6]: train 0.610486 / valid 0.691464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.632289): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:16<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 7]: train 0.600288 / valid 0.691151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.722191): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:14<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 8]: train 0.591795 / valid 0.690235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.646647): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:14<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[ 9]: train 0.584828 / valid 0.689275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model (0.602428): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:13<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step[10]: train 0.579301 / valid 0.689923\n"
     ]
    }
   ],
   "source": [
    "for baseline_param_dict in baseline_params:\n",
    "    train(baseline_param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a50f3",
   "metadata": {},
   "source": [
    "### Testing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e87099",
   "metadata": {},
   "source": [
    "We used three ways to evaluate models as follows:\n",
    "- `mse` is a metric used as an objective for training.\n",
    "- `rmse` is a root of mse which has same scale as predictive variable (rating).\n",
    "- `accuracy` is accuracy of correct discrete rating prediction. Since all reviews have discrete ratings of 1.0, 2.0, 3.0, 4.0 and 5.0, given predictions, we asigned discrete prediction by rounding to nearest integer and calculated accuracy comparing true ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3d3e5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(y_true, y_pred):\n",
    "    return torch.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return torch.sqrt(torch.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def discrete_rating(y_pred):\n",
    "    y_pred = torch.clamp(y_pred, min=0, max=5)\n",
    "    y_pred = torch.round(y_pred)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20321989",
   "metadata": {},
   "source": [
    "For testing, we saved results in csv table so that we can compare models easily, which is saved to `./test_results.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d18b7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_test_results(result):\n",
    "    new_result = pd.Series(result).to_frame().T\n",
    "\n",
    "    if os.path.exists(\"./test_results.csv\"):\n",
    "        results = pd.read_csv(\"./test_results.csv\")\n",
    "\n",
    "        duplicate_index = results[\"name\"] == result[\"name\"]\n",
    "        if sum(duplicate_index) == 0:\n",
    "            results = pd.concat([results, new_result]).reset_index(drop=True)\n",
    "        else:\n",
    "            results = results.values\n",
    "            results[duplicate_index] = new_result.values\n",
    "            results = pd.DataFrame(results, columns=new_result.columns)\n",
    "    else:\n",
    "        results = new_result\n",
    "\n",
    "    print(results)\n",
    "    results.to_csv(\"./test_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bb181dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, test_dataloader, model, device):\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        mse, rmse = 0, 0\n",
    "        n_corrects = 0\n",
    "\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        feat_names = model.feat_names\n",
    "\n",
    "        for feats in test_dataloader:\n",
    "            ratings = feats[-1].to(device)\n",
    "            feats = {name: f.to(device) for name, f in zip(feat_names, feats[:-1])}\n",
    "\n",
    "            pred_ratings = model(feats)\n",
    "\n",
    "            batch_size = feats[\"alpha\"].size(0)\n",
    "            mse += calculate_mse(ratings, pred_ratings).item() * batch_size\n",
    "            rmse += calculate_rmse(ratings, pred_ratings).item() * batch_size\n",
    "\n",
    "            pred_discrete = discrete_rating(pred_ratings)\n",
    "\n",
    "            n_corrects += torch.sum(pred_discrete == ratings).item()\n",
    "            total += batch_size\n",
    "\n",
    "        test_mse = mse / total\n",
    "        test_rmse = rmse / total\n",
    "        test_accuracy = n_corrects / total\n",
    "\n",
    "        return {\"name\": name, \"mse\": test_mse, \"rmse\": test_rmse, \"accuracy\": test_accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809595f",
   "metadata": {},
   "source": [
    "First we evaluate two baseline models:\n",
    "- `MostCommon` just returns most common discrete rating `5`.\n",
    "- `Naive` just returns a global average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1807c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostCommon(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        reviews = pd.read_csv(\"./datasets/splits/test.csv\")\n",
    "\n",
    "        ratings, counts = np.unique(reviews[\"rating\"], return_counts=True)\n",
    "        self.most_common = torch.tensor(ratings[np.argmax(counts)])\n",
    "\n",
    "        self.feat_names = [\"alpha\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.most_common.repeat(x[\"alpha\"].size(0))\n",
    "\n",
    "class Naive(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        reviews = pd.read_csv(\"./datasets/splits/test.csv\")\n",
    "        self.average = torch.tensor(np.mean(reviews[\"rating\"]))\n",
    "\n",
    "        self.feat_names = [\"alpha\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.average.repeat(x[\"alpha\"].size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726c4a1",
   "metadata": {},
   "source": [
    "The following a function to run models on test dataset and save results into `test_results.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8abf6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(param_dict, name=None):\n",
    "    if name == \"most_common\":\n",
    "        model = MostCommon()\n",
    "        feat_names = [\"alpha\"]\n",
    "    elif name == \"naive\":\n",
    "        model = Naive()\n",
    "        feat_names = [\"alpha\"]\n",
    "    else:\n",
    "        feat = param_dict[\"feat\"]\n",
    "        feat_names = param_dict[\"feat_names\"]\n",
    "        lamb_dict = param_dict[\"lamb_dict\"]\n",
    "\n",
    "        test = param_dict[\"test\"]\n",
    "\n",
    "        lamb_str = \"_\".join([f\"{name}-{value}\" for name, value in lamb_dict.items()])\n",
    "        name = f\"{feat}_{lamb_str}\"\n",
    "\n",
    "        if not test:\n",
    "            return\n",
    "\n",
    "        model_path = f\"./models/{name}.pt\"\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            return\n",
    "\n",
    "        print(f\"Loading model from {model_path}\")\n",
    "        model = torch.load(model_path, weights_only=False)\n",
    "\n",
    "    feat_dicts, _ = preprocess_data_latent(feat_names)\n",
    "    test_dataset = CafeDatasetLatent(\"test\", feat_names, feat_dicts)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    result = evaluate_model(name, test_dataloader, model, device)\n",
    "\n",
    "    update_test_results(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1412f78b",
   "metadata": {},
   "source": [
    "Run MostCommon and Naive first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bb2336c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          name       mse      rmse  accuracy\n",
      "0  most_common  1.594156  1.262062  0.523571\n"
     ]
    }
   ],
   "source": [
    "name = \"most_common\"\n",
    "test_model(None, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "25d6090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          name       mse      rmse  accuracy\n",
      "0  most_common  1.594156  1.262062  0.523571\n",
      "1        naive  1.006339  1.003035   0.28008\n"
     ]
    }
   ],
   "source": [
    "test_name = \"naive\"\n",
    "test_model(None, test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6128075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./models/base_alpha-0_user-0.1_cafe-1.pt\n",
      "                           name       mse      rmse  accuracy\n",
      "0                   most_common  1.594156  1.262062  0.523571\n",
      "1                         naive  1.006339  1.003035   0.28008\n",
      "2  base_alpha-0_user-0.1_cafe-1  0.687114   0.82875  0.556383\n",
      "Loading model from ./models/base_latent_alpha-0_user-0.1_cafe-1.pt\n",
      "                                  name       mse      rmse  accuracy\n",
      "0                          most_common  1.594156  1.262062  0.523571\n",
      "1                                naive  1.006339  1.003035   0.28008\n",
      "2         base_alpha-0_user-0.1_cafe-1  0.687114   0.82875  0.556383\n",
      "3  base_latent_alpha-0_user-0.1_cafe-1  0.681222   0.82498  0.559864\n"
     ]
    }
   ],
   "source": [
    "for baseline_param_dict in baseline_params:\n",
    "    test_model(baseline_param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e35ba7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./models/final_alpha-0_user-0.1_cafe-1_chains-0.1_price-0.1_open_hours-0.1_period-0.1.pt\n",
      "                                                name       mse      rmse  \\\n",
      "0                                        most_common  1.594156  1.262062   \n",
      "1                                              naive  1.006339  1.003035   \n",
      "2                       base_alpha-0_user-0.1_cafe-1  0.687114   0.82875   \n",
      "3                base_latent_alpha-0_user-0.1_cafe-1  0.681222   0.82498   \n",
      "4  final_alpha-0_user-0.1_cafe-1_chains-0.1_price...  0.657047  0.810348   \n",
      "\n",
      "   accuracy  \n",
      "0  0.523571  \n",
      "1   0.28008  \n",
      "2  0.556383  \n",
      "3  0.559864  \n",
      "4  0.575418  \n"
     ]
    }
   ],
   "source": [
    "test_model(final_param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987799de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "296f2dfd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "799089c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "474b933b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4acb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b5567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data into notebook\n",
    "cafes, users, reviews = load_table_data()\n",
    "ratings, user2cafes, cafes2users = create_user_review_dicts(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3478a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics:\n",
    "\n",
    "# Get number of users\n",
    "print(\"Number of Users: \", len(users))\n",
    "# Get number of cafes\n",
    "print(\"Number of Cafes: \", len(cafes))\n",
    "# Get number of reviews\n",
    "print(\"Number of Reviews: \", len(reviews))\n",
    "\n",
    "# Format of Cafe Data\n",
    "print(\"CAFE EXAMPLE DATA: \\n\", cafes.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table_data():\n",
    "    cafes = pd.read_csv(\"../datasets/processed/cafes.csv\")\n",
    "    users = pd.read_csv(\"../datasets/processed/users.csv\")\n",
    "    reviews = pd.read_csv(\"../datasets/processed/reviews.csv\")\n",
    "\n",
    "    return cafes, users, reviews\n",
    "\n",
    "def create_user_review_dicts(reviews):\n",
    "    ratings = []\n",
    "    user2cafes = defaultdict(list)\n",
    "    cafe2users = defaultdict(list)\n",
    "\n",
    "    for (user, cafe, rating) in reviews[[\"user_id\", \"gmap_id\", \"rating\"]].values:\n",
    "        ratings.append((user, cafe, rating))\n",
    "        user2cafes[user].append((cafe, rating))\n",
    "        cafe2users[cafe].append((user, rating))\n",
    "\n",
    "\n",
    "    return ratings, user2cafes, cafe2users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization:\n",
    "\n",
    "# Formatting from price using '$' symbol\n",
    "\n",
    "def price_to_num(p):\n",
    "    if pd.isna(p):\n",
    "        return np.nan\n",
    "    p = str(p).strip()\n",
    "    if p == \"\" or p.lower() == \"none\":\n",
    "        return np.nan\n",
    "    n = p.count(\"$\")\n",
    "    return n if n > 0 else np.nan\n",
    "\n",
    "cafes[\"price_num\"] = cafes[\"price\"].apply(price_to_num)\n",
    "cafes[\"price_num\"].value_counts(dropna=False)\n",
    "\n",
    "\n",
    "# Parsing hours if the cafe has them\n",
    "\n",
    "def parse_time_token(tok):\n",
    "    tok = tok.strip().upper() # cleaning text to parse\n",
    "\n",
    "    # Checking 24h like 18:00\n",
    "    m24 = re.match(r\"^(\\d{1,2}):(\\d{2})$\", tok) # trying to match 24-hour format\n",
    "    if m24:\n",
    "        hour, minute = int(m24.group(1)), int(m24.group(2))\n",
    "        return hour*60 + minute\n",
    "\n",
    "    # Checking AM/PM like 7AM, 7:30 PM\n",
    "    m = re.match(r\"^(\\d{1,2})(?::(\\d{2}))?\\s*(AM|PM)$\", tok)\n",
    "    if not m:\n",
    "        return None\n",
    "    hour = int(m.group(1))\n",
    "    minute = int(m.group(2)) if m.group(2) else 0\n",
    "    ampm = m.group(3)\n",
    "    if ampm == \"PM\" and hour != 12: hour += 12\n",
    "    if ampm == \"AM\" and hour == 12: hour = 0\n",
    "    return hour*60 + minute\n",
    "\n",
    "# Converting intervals of hours to a consistent number\n",
    "def interval_to_hours(interval_str):\n",
    "    s = str(interval_str).replace(\"â€“\", \"-\").replace(\"â€”\", \"-\").strip()\n",
    "    if s.lower() in [\"closed\", \"none\", \"nan\", \"\"]:\n",
    "        return 0.0\n",
    "    if \"24 hours\" in s.lower():\n",
    "        return 24.0\n",
    "\n",
    "    parts = [p.strip() for p in s.split(\"-\")]\n",
    "    if len(parts) != 2:\n",
    "        return np.nan\n",
    "\n",
    "    start = parse_time_token(parts[0])\n",
    "    end = parse_time_token(parts[1])\n",
    "    if start is None or end is None:\n",
    "        return np.nan\n",
    "\n",
    "    if end < start:  # Overnight\n",
    "        end += 24*60\n",
    "    return (end - start) / 60.0\n",
    "\n",
    "# Summing weeks hours\n",
    "def hours_to_weekly_total(hours_field):\n",
    "    if pd.isna(hours_field): # returning nan if no hours exist for cafe\n",
    "        return np.nan\n",
    "    try:\n",
    "        data = ast.literal_eval(hours_field) if isinstance(hours_field, str) else hours_field\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "    if not isinstance(data, (list, tuple)):\n",
    "        return np.nan\n",
    "\n",
    "    total = 0.0\n",
    "    for item in data:\n",
    "        if not item or len(item) < 2:\n",
    "            continue\n",
    "        intervals = item[1]\n",
    "        if isinstance(intervals, str):\n",
    "            total += interval_to_hours(intervals)\n",
    "        elif isinstance(intervals, (list, tuple)): # if the cafe has multiple intervals of open times\n",
    "            for inter in intervals:\n",
    "                total += interval_to_hours(inter)\n",
    "    return total\n",
    "\n",
    "cafes[\"weekly_hours\"] = cafes[\"hours\"].apply(hours_to_weekly_total)\n",
    "cafes[\"avg_daily_hours\"] = cafes[\"weekly_hours\"] / 7.0\n",
    "\n",
    "cafes[[\"hours\",\"weekly_hours\",\"avg_daily_hours\"]].head(3)\n",
    "\n",
    "\n",
    "# Combining cafes and reviews\n",
    "\n",
    "df = reviews.merge(\n",
    "    cafes[[\"gmap_id\",\"name\",\"latitude\",\"longitude\",\"price_num\",\"avg_daily_hours\",\"avg_rating\"]],\n",
    "    on=\"gmap_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "# Hours vs Rating - data prep\n",
    "\n",
    "cafe_avg = df.groupby(\"gmap_id\").agg(\n",
    "    avg_user_rating=(\"rating\",\"mean\"),\n",
    "    avg_daily_hours=(\"avg_daily_hours\",\"first\"),\n",
    ").dropna()\n",
    "\n",
    "bins_hours = pd.cut(cafe_avg[\"avg_daily_hours\"], bins=10)\n",
    "binned_hours = cafe_avg.groupby(bins_hours)[\"avg_user_rating\"].mean()\n",
    "\n",
    "\n",
    "# Review time vs Average Rating - data prep\n",
    "\n",
    "reviews_time = reviews.copy()\n",
    "\n",
    "# making sure the rating is numeric\n",
    "reviews_time[\"rating\"] = pd.to_numeric(reviews_time[\"rating\"], errors=\"coerce\")\n",
    "\n",
    "# converting Unix ms to datetime\n",
    "reviews_time[\"timestamp\"] = pd.to_datetime(\n",
    "    reviews_time[\"time\"],\n",
    "    unit=\"ms\"\n",
    ")\n",
    "\n",
    "reviews_time[\"date\"] = reviews_time[\"timestamp\"].dt.date\n",
    "reviews_time[\"month\"] = reviews_time[\"timestamp\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "# computing average rating per month and number of reviews per month\n",
    "time_stats_all = (\n",
    "    reviews_time\n",
    "        .dropna(subset=[\"rating\"])\n",
    "        .groupby(\"month\")\n",
    "        .agg(\n",
    "            avg_rating=(\"rating\", \"mean\"),\n",
    "            num_reviews=(\"rating\", \"count\")\n",
    "        )\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "min_reviews = 100  # change to change the number of minimum reviews needed\n",
    "ts_global = time_stats_all[\n",
    "    (time_stats_all[\"num_reviews\"] >= min_reviews)\n",
    "    & (time_stats_all[\"month\"] >= \"2008-01-01\") # change to change time period, set at 2008 and after currently\n",
    "].sort_values(\"month\")\n",
    "\n",
    "\n",
    "# Review Time vs Average Rating (3 Time Periods) - data prep\n",
    "\n",
    "# Creating time boundaries // can change if we want\n",
    "boundary_2016 = pd.Timestamp(\"2016-01-01\")\n",
    "boundary_2020 = pd.Timestamp(\"2020-01-01\")\n",
    "\n",
    "def unix_ms_to_period(unix_ms):\n",
    "    \"\"\"\n",
    "      0 -> before 2016\n",
    "      1 -> 2016-2019\n",
    "      2 -> 2020 and later\n",
    "    \"\"\"\n",
    "    if pd.isna(unix_ms):\n",
    "        return np.nan\n",
    "    try:\n",
    "        t = int(unix_ms)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "    b2016_ms = int(pd.Timestamp(\"2016-01-01\").timestamp() * 1000)\n",
    "    b2020_ms = int(pd.Timestamp(\"2020-01-01\").timestamp() * 1000)\n",
    "\n",
    "    if t < b2016_ms:\n",
    "        return 0\n",
    "    elif t < b2020_ms:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# adding numeric time-period feature to reviews\n",
    "reviews[\"time_period\"] = reviews[\"time\"].apply(unix_ms_to_period)\n",
    "\n",
    "# Label function for plotting\n",
    "def label_period(ts):\n",
    "    if ts < boundary_2016:\n",
    "        return \"pre-2016\"\n",
    "    elif ts < boundary_2020:\n",
    "        return \"2016-2019\"\n",
    "    else:\n",
    "        return \"2020+\"\n",
    "\n",
    "time_stats_period = time_stats_all.copy()\n",
    "time_stats_period[\"period\"] = time_stats_period[\"month\"].apply(label_period)\n",
    "\n",
    "\n",
    "# Price vs Rating - data prep\n",
    "\n",
    "cafe_avg_price = df.groupby(\"gmap_id\").agg(\n",
    "    avg_user_rating=(\"rating\",\"mean\"),\n",
    "    price_num=(\"price_num\",\"first\")\n",
    ").dropna()\n",
    "\n",
    "levels = sorted(cafe_avg_price[\"price_num\"].unique())\n",
    "means = cafe_avg_price.groupby(\"price_num\")[\"avg_user_rating\"].mean()\n",
    "\n",
    "\n",
    "# Creating big figure with all graphs\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 0: Open hours vs rating\n",
    "ax = axes[0]\n",
    "ax.scatter(cafe_avg[\"avg_daily_hours\"], cafe_avg[\"avg_user_rating\"], alpha=0.35)\n",
    "ax.set_xlabel(\"Avg daily open hours\")\n",
    "ax.set_ylabel(\"Average review rating\")\n",
    "ax.set_title(\"Open hours vs rating (cafe-level)\")\n",
    "\n",
    "# 1: Binned open hours vs rating\n",
    "ax = axes[1]\n",
    "ax.plot(binned_hours.index.astype(str), binned_hours.values, marker=\"o\")\n",
    "ax.set_xlabel(\"Avg daily hours (binned)\")\n",
    "ax.set_ylabel(\"Mean rating\")\n",
    "ax.set_title(\"Binned open hours vs rating\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# 2: Average review rating over time\n",
    "ax = axes[2]\n",
    "ax.plot(ts_global[\"month\"], ts_global[\"avg_rating\"], marker=\"o\", linestyle=\"-\")\n",
    "ax.set_xlabel(\"Review month\")\n",
    "ax.set_ylabel(\"Average rating\")\n",
    "ax.set_title(\"Average review rating over time\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "ax.set_ylim(3.0, 5.0)  # Dictating the rating range to be only 3 - 5 so we can see changes in graph\n",
    "\n",
    "# 3: Number of reviews per month\n",
    "ax = axes[3]\n",
    "ax.plot(ts_global[\"month\"], ts_global[\"num_reviews\"], marker=\"o\", linestyle=\"-\")\n",
    "ax.set_xlabel(\"Review month\")\n",
    "ax.set_ylabel(\"# Reviews\")\n",
    "ax.set_title(\"Number of reviews per month\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# 4â€“6: Average review rating over time (split into 3 time periods)\n",
    "period_order = [\"pre-2016\", \"2016-2019\", \"2020+\"]\n",
    "for idx, label in enumerate(period_order, start=4):\n",
    "    ax = axes[idx]\n",
    "    ts = time_stats_period[time_stats_period[\"period\"] == label].copy()\n",
    "    ts = ts[ts[\"num_reviews\"] >= min_reviews]\n",
    "    if ts.empty:\n",
    "        ax.set_visible(False)\n",
    "        continue  # in case the early period has no data\n",
    "\n",
    "    ts = ts.sort_values(\"month\")\n",
    "    ax.plot(ts[\"month\"], ts[\"avg_rating\"], marker=\"o\", linestyle=\"-\")\n",
    "    ax.set_xlabel(\"Review month\")\n",
    "    ax.set_ylabel(\"Average rating\")\n",
    "    ax.set_title(f\"Average review rating over time ({label})\")\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "    ax.set_ylim(3.0, 5.1)  # focusing on reasonable ratings // can change\n",
    "\n",
    "# 7: Price vs rating\n",
    "ax = axes[7]\n",
    "ax.boxplot(\n",
    "    [cafe_avg_price[cafe_avg_price[\"price_num\"]==k][\"avg_user_rating\"] for k in levels],\n",
    "    labels=[int(k) for k in levels]\n",
    ")\n",
    "ax.set_xlabel(\"Price level (# of $)\")\n",
    "ax.set_ylabel(\"Average review rating\")\n",
    "ax.set_title(\"Price vs rating (cafe-level)\")\n",
    "\n",
    "# 8: Mean rating by price level\n",
    "ax = axes[8]\n",
    "ax.bar(means.index.astype(int), means.values)\n",
    "ax.set_xlabel(\"Price level (# of $)\")\n",
    "ax.set_ylabel(\"Mean rating\")\n",
    "ax.set_title(\"Mean rating by price level\")\n",
    "\n",
    "fig.suptitle(\"Cafe Data Visualizations\", fontsize=16, y=0.98)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folium Visualization:\n",
    "\n",
    "cafes_map = cafes.dropna(subset=[\"latitude\",\"longitude\"]).copy()\n",
    "cafes_map[\"avg_rating\"] = pd.to_numeric(cafes_map[\"avg_rating\"], errors=\"coerce\")\n",
    "\n",
    "# base map\n",
    "map = folium.Map(\n",
    "    location=[36.5, -119.5],\n",
    "    zoom_start=6\n",
    ")\n",
    "\n",
    "# california outline from github\n",
    "ca_geojson_url = \"https://raw.githubusercontent.com/glynnbird/usstatesgeojson/master/california.geojson\"\n",
    "\n",
    "folium.GeoJson(\n",
    "    ca_geojson_url,\n",
    "    name=\"California outline\",\n",
    "    style_function=lambda feature: {\n",
    "        \"fillColor\": \"#ffffff\",\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 3,\n",
    "        \"fillOpacity\": 0.05\n",
    "    }\n",
    ").add_to(map)\n",
    "\n",
    "# california counties from github\n",
    "counties_url = \"https://raw.githubusercontent.com/codeforamerica/click_that_hood/master/public/data/california-counties.geojson\"\n",
    "counties_geo = requests.get(counties_url).json()\n",
    "\n",
    "# converting counties to polygons for averages\n",
    "county_polys = []\n",
    "for feat in counties_geo[\"features\"]:\n",
    "    county_name = feat[\"properties\"][\"name\"]\n",
    "    poly = prep(shape(feat[\"geometry\"]))\n",
    "    county_polys.append((county_name, poly))\n",
    "\n",
    "# assigning county to each cafe based on lat/long\n",
    "def find_county(lat, long):\n",
    "    pt = Point(long, lat)\n",
    "    for cname, poly in county_polys:\n",
    "        if poly.contains(pt):\n",
    "            return cname\n",
    "    return np.nan\n",
    "\n",
    "cafes_map[\"county\"] = cafes_map.apply(\n",
    "    lambda r: find_county(r[\"latitude\"], r[\"longitude\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# getting average rating per county\n",
    "county_stats = (\n",
    "    cafes_map.dropna(subset=[\"county\"]) # removes cafes without county label so they aren't computed in average\n",
    "             .groupby(\"county\")\n",
    "             .agg(avg_rating=(\"avg_rating\", \"mean\"))\n",
    "             .reset_index()\n",
    ")\n",
    "\n",
    "# choropleth coloring counties by average rating\n",
    "folium.Choropleth(\n",
    "    geo_data=counties_geo,\n",
    "    name=\"Average rating per county\",\n",
    "    data=county_stats,\n",
    "    columns=[\"county\", \"avg_rating\"],\n",
    "    key_on=\"feature.properties.name\",\n",
    "    fill_color=\"YlGnBu\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.3,\n",
    "    nan_fill_color=\"white\",\n",
    "    legend_name=\"Average cafe rating\"\n",
    ").add_to(map)\n",
    "\n",
    "# cafe markers\n",
    "cluster = MarkerCluster(name=\"Cafe markers\").add_to(map)\n",
    "\n",
    "for _, r in cafes_map.iterrows():\n",
    "    popup = (\n",
    "        f\"{r.get('name','')}\"\n",
    "        f\"<br>Rating: {r.get('avg_rating',np.nan)}\"\n",
    "        f\"<br>Price: {r.get('price','')}\"\n",
    "        f\"<br>County: {r.get('county','')}\"\n",
    "    )\n",
    "    folium.CircleMarker(\n",
    "        location=[r[\"latitude\"], r[\"longitude\"]],\n",
    "        radius=2.5,\n",
    "        color=\"black\",\n",
    "        weight=0.5,\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        popup=popup\n",
    "    ).add_to(cluster)\n",
    "\n",
    "# Toggle panel so we can show/hide features\n",
    "folium.LayerControl(collapsed=False).add_to(map)\n",
    "map\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
