{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f928e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc5e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import load_datasets\n",
    "import re\n",
    "import ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41def05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# County Data - Load county shapefile (California only)\n",
    "counties = gpd.read_file(\"resources/cb_2018_us_county_500k.shp\")\n",
    "counties_ca = counties[counties[\"STATEFP\"] == \"06\"]  # 06 = California\n",
    "counties_ca = counties_ca.sort_values(\"NAME\").reset_index(drop=True)\n",
    "counties_ca[\"COUNTY_NUM\"] = counties_ca.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data into notebook\n",
    "cafes, users, reviews = load_datasets.load_table_data()\n",
    "ratings, user2cafes, cafes2users = load_datasets.create_user_review_dicts(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SECTION 1 - DATA ANALYTICS ###\n",
    "# This section looks at various statistics about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f1987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users:  196454\n",
      "Number of Cafes:  15576\n",
      "Number of Reviews:  1769673\n",
      "\n",
      "USER EXAMPLE DATA: \n",
      " user_id        100000041656879737279\n",
      "num_reviews                        7\n",
      "Name: 0, dtype: object \n",
      "\n",
      "CAFE EXAMPLE DATA: \n",
      " gmap_id                       0x80dc976f028eb61d:0x1a5ed32889a67122\n",
      "name                                                       Circle K\n",
      "latitude                                                  33.689862\n",
      "longitude                                               -117.376151\n",
      "category          ['Convenience store', 'ATM', 'Coffee shop', 'C...\n",
      "avg_rating                                                      3.5\n",
      "num_of_reviews                                                   24\n",
      "price                                                             $\n",
      "hours             [['Thursday', 'Open 24 hours'], ['Friday', 'Op...\n",
      "Name: 0, dtype: object \n",
      "\n",
      "REVIEW EXAMPLE DATA: \n",
      " gmap_id                  0x80dc976f028eb61d:0x1a5ed32889a67122\n",
      "user_id                                  108984874068893102454\n",
      "name                                                  john b89\n",
      "time                                             1625418305938\n",
      "rating                                                     5.0\n",
      "review_id    108984874068893102454_0x80dc976f028eb61d:0x1a5...\n",
      "Name: 0, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basics:\n",
    "\n",
    "# Get number of users\n",
    "print(\"Number of Users: \", len(users))\n",
    "# Get number of cafes\n",
    "print(\"Number of Cafes: \", len(cafes))\n",
    "# Get number of reviews\n",
    "print(\"Number of Reviews: \", len(reviews))\n",
    "\n",
    "# Format of User Data\n",
    "print(\"\\nUSER EXAMPLE DATA: \\n\", users.iloc[0,:], \"\\n\")\n",
    "# Format of Cafe Data\n",
    "print(\"CAFE EXAMPLE DATA: \\n\", cafes.iloc[0,:], \"\\n\")\n",
    "# Format of Review\n",
    "print(\"REVIEW EXAMPLE DATA: \\n\", reviews.iloc[0,:], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8a1756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions:\n",
    "\n",
    "# Average rating\n",
    "def avg_rating(df):\n",
    "    return sum(df['rating']) / len(df['rating'])\n",
    "\n",
    "# Average price\n",
    "def avg_price(df):\n",
    "    return sum(df['price']) / len(df['price'])\n",
    "\n",
    "# Converts time text to values\n",
    "def parse_time(t):\n",
    "    t = t.strip().upper()\n",
    "\n",
    "    # Match hh or hh:mm formats\n",
    "    m = re.match(r\"(\\d{1,2})(?::(\\d{2}))?(AM|PM)\", t)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Invalid time format: {t}\")\n",
    "\n",
    "    hour = int(m.group(1))\n",
    "    minute = int(m.group(2) or 0)\n",
    "    period = m.group(3)\n",
    "\n",
    "    # Convert to 24-hour\n",
    "    if period == \"AM\":\n",
    "        if hour == 12:\n",
    "            hour = 0\n",
    "    else:  # PM\n",
    "        if hour != 12:\n",
    "            hour += 12\n",
    "\n",
    "    return hour + minute / 60.0\n",
    "\n",
    "# County Mapping Based on Latitude & Longitude\n",
    "def get_county(lat, lon):\n",
    "    point = Point(lon, lat)  # geometry expects (lon, lat)\n",
    "    matches = counties_ca[counties_ca.contains(point)]\n",
    "\n",
    "    if len(matches) > 0:\n",
    "        return int(matches.iloc[0][\"COUNTY_NUM\"])\n",
    "    return None\n",
    "\n",
    "# Gets County Name Based on Latitude & Longitude\n",
    "def get_county_name(lat, lon):\n",
    "    county_num = get_county(lat,lon)\n",
    "    return counties_ca[counties_ca[\"COUNTY_NUM\"] == county_num][\"NAME\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e50fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization:\n",
    "\n",
    "# Formatting from price using '$' symbol\n",
    "\n",
    "def price_to_num(p):\n",
    "    if pd.isna(p):\n",
    "        return np.nan\n",
    "    p = str(p).strip()\n",
    "    if p == \"\" or p.lower() == \"none\":\n",
    "        return np.nan\n",
    "    n = p.count(\"$\")\n",
    "    return n if n > 0 else np.nan\n",
    "\n",
    "cafes[\"price_num\"] = cafes[\"price\"].apply(price_to_num)\n",
    "cafes[\"price_num\"].value_counts(dropna=False)\n",
    "\n",
    "\n",
    "# Parsing hours if the cafe has them\n",
    "\n",
    "def parse_time_token(tok):\n",
    "    tok = tok.strip().upper() # cleaning text to parse\n",
    "    \n",
    "    # Checking 24h like 18:00\n",
    "    m24 = re.match(r\"^(\\d{1,2}):(\\d{2})$\", tok) # trying to match 24-hour format\n",
    "    if m24:\n",
    "        hour, minute = int(m24.group(1)), int(m24.group(2))\n",
    "        return hour*60 + minute\n",
    "\n",
    "    # Checking AM/PM like 7AM, 7:30 PM\n",
    "    m = re.match(r\"^(\\d{1,2})(?::(\\d{2}))?\\s*(AM|PM)$\", tok)\n",
    "    if not m:\n",
    "        return None\n",
    "    hour = int(m.group(1))\n",
    "    minute = int(m.group(2)) if m.group(2) else 0\n",
    "    ampm = m.group(3)\n",
    "    if ampm == \"PM\" and hour != 12: hour += 12\n",
    "    if ampm == \"AM\" and hour == 12: hour = 0\n",
    "    return hour*60 + minute\n",
    "\n",
    "# Converting intervals of hours to a consistent number\n",
    "def interval_to_hours(interval_str):\n",
    "    s = str(interval_str).replace(\"–\", \"-\").replace(\"—\", \"-\").strip()\n",
    "    if s.lower() in [\"closed\", \"none\", \"nan\", \"\"]:\n",
    "        return 0.0\n",
    "    if \"24 hours\" in s.lower():\n",
    "        return 24.0\n",
    "\n",
    "    parts = [p.strip() for p in s.split(\"-\")]\n",
    "    if len(parts) != 2:\n",
    "        return np.nan\n",
    "\n",
    "    start = parse_time_token(parts[0])\n",
    "    end = parse_time_token(parts[1])\n",
    "    if start is None or end is None:\n",
    "        return np.nan\n",
    "\n",
    "    if end < start:  # Overnight\n",
    "        end += 24*60\n",
    "    return (end - start) / 60.0\n",
    "\n",
    "# Summing weeks hours\n",
    "def hours_to_weekly_total(hours_field):\n",
    "    if pd.isna(hours_field): # returning nan if no hours exist for cafe\n",
    "        return np.nan \n",
    "    try:\n",
    "        data = ast.literal_eval(hours_field) if isinstance(hours_field, str) else hours_field\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "    if not isinstance(data, (list, tuple)):\n",
    "        return np.nan\n",
    "\n",
    "    total = 0.0\n",
    "    for item in data:\n",
    "        if not item or len(item) < 2:\n",
    "            continue\n",
    "        intervals = item[1]\n",
    "        if isinstance(intervals, str):\n",
    "            total += interval_to_hours(intervals)\n",
    "        elif isinstance(intervals, (list, tuple)): # if the cafe has multiple intervals of open times\n",
    "            for inter in intervals:\n",
    "                total += interval_to_hours(inter)\n",
    "    return total\n",
    "\n",
    "cafes[\"weekly_hours\"] = cafes[\"hours\"].apply(hours_to_weekly_total)\n",
    "cafes[\"avg_daily_hours\"] = cafes[\"weekly_hours\"] / 7.0\n",
    "\n",
    "cafes[[\"hours\",\"weekly_hours\",\"avg_daily_hours\"]].head(3)\n",
    "\n",
    "\n",
    "# Combining cafes and reviews\n",
    "\n",
    "df = reviews.merge(\n",
    "    cafes[[\"gmap_id\",\"name\",\"latitude\",\"longitude\",\"price_num\",\"avg_daily_hours\",\"avg_rating\"]],\n",
    "    on=\"gmap_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "# Hours vs Rating - data prep\n",
    "\n",
    "cafe_avg = df.groupby(\"gmap_id\").agg(\n",
    "    avg_user_rating=(\"rating\",\"mean\"),\n",
    "    avg_daily_hours=(\"avg_daily_hours\",\"first\"),\n",
    ").dropna()\n",
    "\n",
    "bins_hours = pd.cut(cafe_avg[\"avg_daily_hours\"], bins=10)\n",
    "binned_hours = cafe_avg.groupby(bins_hours)[\"avg_user_rating\"].mean()\n",
    "\n",
    "\n",
    "# Review time vs Average Rating - data prep\n",
    "\n",
    "reviews_time = reviews.copy()\n",
    "\n",
    "# making sure the rating is numeric\n",
    "reviews_time[\"rating\"] = pd.to_numeric(reviews_time[\"rating\"], errors=\"coerce\")\n",
    "\n",
    "# converting Unix ms to datetime\n",
    "reviews_time[\"timestamp\"] = pd.to_datetime(\n",
    "    reviews_time[\"time\"],\n",
    "    unit=\"ms\"\n",
    ")\n",
    "\n",
    "reviews_time[\"date\"] = reviews_time[\"timestamp\"].dt.date\n",
    "reviews_time[\"month\"] = reviews_time[\"timestamp\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "# computing average rating per month and number of reviews per month\n",
    "time_stats_all = (\n",
    "    reviews_time\n",
    "        .dropna(subset=[\"rating\"])\n",
    "        .groupby(\"month\")\n",
    "        .agg(\n",
    "            avg_rating=(\"rating\", \"mean\"),\n",
    "            num_reviews=(\"rating\", \"count\")\n",
    "        )\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "min_reviews = 100  # change to change the number of minimum reviews needed\n",
    "ts_global = time_stats_all[\n",
    "    (time_stats_all[\"num_reviews\"] >= min_reviews)\n",
    "    & (time_stats_all[\"month\"] >= \"2008-01-01\") # change to change time period, set at 2008 and after currently\n",
    "].sort_values(\"month\")\n",
    "\n",
    "\n",
    "# Review Time vs Average Rating (3 Time Periods) - data prep\n",
    "\n",
    "# Creating time boundaries // can change if we want\n",
    "boundary_2016 = pd.Timestamp(\"2016-01-01\")\n",
    "boundary_2020 = pd.Timestamp(\"2020-01-01\")\n",
    "\n",
    "def unix_ms_to_period(unix_ms):\n",
    "    \"\"\"\n",
    "      0 -> before 2016\n",
    "      1 -> 2016-2019\n",
    "      2 -> 2020 and later\n",
    "    \"\"\"\n",
    "    if pd.isna(unix_ms):\n",
    "        return np.nan\n",
    "    try:\n",
    "        t = int(unix_ms)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "    \n",
    "    b2016_ms = int(pd.Timestamp(\"2016-01-01\").timestamp() * 1000)\n",
    "    b2020_ms = int(pd.Timestamp(\"2020-01-01\").timestamp() * 1000)\n",
    "\n",
    "    if t < b2016_ms:\n",
    "        return 0\n",
    "    elif t < b2020_ms:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# adding numeric time-period feature to reviews\n",
    "reviews[\"time_period\"] = reviews[\"time\"].apply(unix_ms_to_period)\n",
    "\n",
    "# Label function for plotting\n",
    "def label_period(ts):\n",
    "    if ts < boundary_2016:\n",
    "        return \"pre-2016\"\n",
    "    elif ts < boundary_2020:\n",
    "        return \"2016-2019\"\n",
    "    else:\n",
    "        return \"2020+\"\n",
    "\n",
    "time_stats_period = time_stats_all.copy()\n",
    "time_stats_period[\"period\"] = time_stats_period[\"month\"].apply(label_period)\n",
    "\n",
    "\n",
    "# Price vs Rating - data prep\n",
    "\n",
    "cafe_avg_price = df.groupby(\"gmap_id\").agg(\n",
    "    avg_user_rating=(\"rating\",\"mean\"),\n",
    "    price_num=(\"price_num\",\"first\")\n",
    ").dropna()\n",
    "\n",
    "levels = sorted(cafe_avg_price[\"price_num\"].unique())\n",
    "means = cafe_avg_price.groupby(\"price_num\")[\"avg_user_rating\"].mean()\n",
    "\n",
    "\n",
    "# Creating big figure with all graphs\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 0: Open hours vs rating\n",
    "ax = axes[0]\n",
    "ax.scatter(cafe_avg[\"avg_daily_hours\"], cafe_avg[\"avg_user_rating\"], alpha=0.35)\n",
    "ax.set_xlabel(\"Avg daily open hours\")\n",
    "ax.set_ylabel(\"Average review rating\")\n",
    "ax.set_title(\"Open hours vs rating (cafe-level)\")\n",
    "\n",
    "# 1: Binned open hours vs rating\n",
    "ax = axes[1]\n",
    "ax.plot(binned_hours.index.astype(str), binned_hours.values, marker=\"o\")\n",
    "ax.set_xlabel(\"Avg daily hours (binned)\")\n",
    "ax.set_ylabel(\"Mean rating\")\n",
    "ax.set_title(\"Binned open hours vs rating\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# 2: Average review rating over time\n",
    "ax = axes[2]\n",
    "ax.plot(ts_global[\"month\"], ts_global[\"avg_rating\"], marker=\"o\", linestyle=\"-\")\n",
    "ax.set_xlabel(\"Review month\")\n",
    "ax.set_ylabel(\"Average rating\")\n",
    "ax.set_title(\"Average review rating over time\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "ax.set_ylim(3.0, 5.0)  # Dictating the rating range to be only 3 - 5 so we can see changes in graph\n",
    "\n",
    "# 3: Number of reviews per month\n",
    "ax = axes[3]\n",
    "ax.plot(ts_global[\"month\"], ts_global[\"num_reviews\"], marker=\"o\", linestyle=\"-\")\n",
    "ax.set_xlabel(\"Review month\")\n",
    "ax.set_ylabel(\"# Reviews\")\n",
    "ax.set_title(\"Number of reviews per month\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# 4–6: Average review rating over time (split into 3 time periods)\n",
    "period_order = [\"pre-2016\", \"2016-2019\", \"2020+\"]\n",
    "for idx, label in enumerate(period_order, start=4):\n",
    "    ax = axes[idx]\n",
    "    ts = time_stats_period[time_stats_period[\"period\"] == label].copy()\n",
    "    ts = ts[ts[\"num_reviews\"] >= min_reviews]\n",
    "    if ts.empty:\n",
    "        ax.set_visible(False)\n",
    "        continue  # in case the early period has no data\n",
    "\n",
    "    ts = ts.sort_values(\"month\")\n",
    "    ax.plot(ts[\"month\"], ts[\"avg_rating\"], marker=\"o\", linestyle=\"-\")\n",
    "    ax.set_xlabel(\"Review month\")\n",
    "    ax.set_ylabel(\"Average rating\")\n",
    "    ax.set_title(f\"Average review rating over time ({label})\")\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "    ax.set_ylim(3.0, 5.1)  # focusing on reasonable ratings // can change\n",
    "\n",
    "# 7: Price vs rating\n",
    "ax = axes[7]\n",
    "ax.boxplot(\n",
    "    [cafe_avg_price[cafe_avg_price[\"price_num\"]==k][\"avg_user_rating\"] for k in levels],\n",
    "    labels=[int(k) for k in levels]\n",
    ")\n",
    "ax.set_xlabel(\"Price level (# of $)\")\n",
    "ax.set_ylabel(\"Average review rating\")\n",
    "ax.set_title(\"Price vs rating (cafe-level)\")\n",
    "\n",
    "# 8: Mean rating by price level\n",
    "ax = axes[8]\n",
    "ax.bar(means.index.astype(int), means.values)\n",
    "ax.set_xlabel(\"Price level (# of $)\")\n",
    "ax.set_ylabel(\"Mean rating\")\n",
    "ax.set_title(\"Mean rating by price level\")\n",
    "\n",
    "fig.suptitle(\"Cafe Data Visualizations\", fontsize=16, y=0.98)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folium Visualization:\n",
    "\n",
    "cafes_map = cafes.dropna(subset=[\"latitude\",\"longitude\"]).copy()\n",
    "cafes_map[\"avg_rating\"] = pd.to_numeric(cafes_map[\"avg_rating\"], errors=\"coerce\")\n",
    "\n",
    "# base map\n",
    "map = folium.Map(\n",
    "    location=[36.5, -119.5],\n",
    "    zoom_start=6\n",
    ")\n",
    "\n",
    "# california outline from github\n",
    "ca_geojson_url = \"https://raw.githubusercontent.com/glynnbird/usstatesgeojson/master/california.geojson\"\n",
    "\n",
    "folium.GeoJson(\n",
    "    ca_geojson_url,\n",
    "    name=\"California outline\",\n",
    "    style_function=lambda feature: {\n",
    "        \"fillColor\": \"#ffffff\",\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 3,\n",
    "        \"fillOpacity\": 0.05\n",
    "    }\n",
    ").add_to(map)\n",
    "\n",
    "# california counties from github\n",
    "counties_url = \"https://raw.githubusercontent.com/codeforamerica/click_that_hood/master/public/data/california-counties.geojson\"\n",
    "counties_geo = requests.get(counties_url).json()\n",
    "\n",
    "# converting counties to polygons for averages\n",
    "county_polys = []\n",
    "for feat in counties_geo[\"features\"]:\n",
    "    county_name = feat[\"properties\"][\"name\"]\n",
    "    poly = prep(shape(feat[\"geometry\"]))\n",
    "    county_polys.append((county_name, poly))\n",
    "\n",
    "# assigning county to each cafe based on lat/long\n",
    "def find_county(lat, long):\n",
    "    pt = Point(long, lat)\n",
    "    for cname, poly in county_polys:\n",
    "        if poly.contains(pt):\n",
    "            return cname\n",
    "    return np.nan\n",
    "\n",
    "cafes_map[\"county\"] = cafes_map.apply(\n",
    "    lambda r: find_county(r[\"latitude\"], r[\"longitude\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# getting average rating per county\n",
    "county_stats = (\n",
    "    cafes_map.dropna(subset=[\"county\"]) # removes cafes without county label so they aren't computed in average\n",
    "             .groupby(\"county\")\n",
    "             .agg(avg_rating=(\"avg_rating\", \"mean\"))\n",
    "             .reset_index()\n",
    ")\n",
    "\n",
    "# choropleth coloring counties by average rating\n",
    "folium.Choropleth(\n",
    "    geo_data=counties_geo,\n",
    "    name=\"Average rating per county\",\n",
    "    data=county_stats,\n",
    "    columns=[\"county\", \"avg_rating\"],\n",
    "    key_on=\"feature.properties.name\",\n",
    "    fill_color=\"YlGnBu\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.3,\n",
    "    nan_fill_color=\"white\",\n",
    "    legend_name=\"Average cafe rating\"\n",
    ").add_to(map)\n",
    "\n",
    "# cafe markers\n",
    "cluster = MarkerCluster(name=\"Cafe markers\").add_to(map)\n",
    "\n",
    "for _, r in cafes_map.iterrows():\n",
    "    popup = (\n",
    "        f\"{r.get('name','')}\"\n",
    "        f\"<br>Rating: {r.get('avg_rating',np.nan)}\"\n",
    "        f\"<br>Price: {r.get('price','')}\"\n",
    "        f\"<br>County: {r.get('county','')}\"\n",
    "    )\n",
    "    folium.CircleMarker(\n",
    "        location=[r[\"latitude\"], r[\"longitude\"]],\n",
    "        radius=2.5,\n",
    "        color=\"black\",\n",
    "        weight=0.5,\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        popup=popup\n",
    "    ).add_to(cluster)\n",
    "\n",
    "# Toggle panel so we can show/hide features\n",
    "folium.LayerControl(collapsed=False).add_to(map)\n",
    "map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SECTION 2 - Data Processing ###\n",
    "# This section processes the data to prepare it for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin Encoding for Hours Throughout Week\n",
    "def hours_to_onehot(datum):\n",
    "    feature_hours = [0]*24*7        # Feature vector is 168 wide (24 hours by 7 days)\n",
    "    hours = ast.literal_eval(datum['hours'])\n",
    "\n",
    "    weekday_map = {\n",
    "        \"Monday\" : 0,\n",
    "        \"Tuesday\" : 1,\n",
    "        \"Wednesday\" : 2,\n",
    "        \"Thursday\" : 3,\n",
    "        \"Friday\" : 4,\n",
    "        \"Saturday\" : 5,\n",
    "        \"Sunday\" :6\n",
    "    }\n",
    "\n",
    "    for entry in hours:\n",
    "        day = weekday_map[entry[0]] # Gets day of week number\n",
    "\n",
    "        # Closed, skip entry\n",
    "        if entry[1] == \"Closed\":\n",
    "            continue\n",
    "\n",
    "        # Open 24 hours, all ones\n",
    "        if entry[1] == \"Open 24 hours\":\n",
    "            for d in range(day*24,day*24+24): feature_hours[d] = 1\n",
    "            continue\n",
    "\n",
    "        # Converts entry to range of hours\n",
    "        open_str, close_str = entry[1].split(\"–\")\n",
    "        start_hr = int(np.floor(parse_time(open_str)))\n",
    "        end_hr = int(np.ceil(parse_time(close_str)))\n",
    "\n",
    "        for hr in range(start_hr, end_hr):\n",
    "            index = day * 24 + hr\n",
    "            feature_hours[index] = 1\n",
    "\n",
    "    return feature_hours\n",
    "\n",
    "\n",
    "# One Hot Encoding for Price\n",
    "def price_to_onehot(datum):\n",
    "    feature_price = [0]*3\n",
    "    if datum['price'] is not np.nan:\n",
    "        feature_price[len(datum['price'])-1] += 1\n",
    "    return feature_price\n",
    "\n",
    "# One Hot Encoding for County\n",
    "def county_to_onehot(datum):\n",
    "    # To check functionality, chose entry 863 which is SFO - should map to San Mateo County\n",
    "    feature_county =[0]*58  # 58 counties in Cali\n",
    "\n",
    "    index = get_county(datum['latitude'],datum['longitude'])\n",
    "    feature_county[index] = 1\n",
    "\n",
    "    return feature_county\n",
    "\n",
    "# One Hot Encoding for Unix Time Weekday\n",
    "def unix_weekday_to_onehot(datum):\n",
    "    feature_weekday = [0]*7\n",
    "\n",
    "    day = datetime.fromtimestamp(datum['time'] / 1000, tz=timezone.utc).weekday()\n",
    "    print(day)\n",
    "    feature_weekday[day] = 1\n",
    "\n",
    "    return feature_weekday\n",
    "\n",
    "# One Hot Encoding for Unix Time Hour\n",
    "def unix_hour_to_onehot(datum):\n",
    "    feature_dayhour = [0]*24\n",
    "\n",
    "    hr = datetime.fromtimestamp(datum['time'] / 1000, tz=timezone.utc).hour\n",
    "    feature_dayhour[hr] = 1\n",
    "\n",
    "    return feature_dayhour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2de992e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmap_id                       0x808f7790a747d34d:0x368adb21c5e27122\n",
      "name              Green Beans Coffee - San Francisco Internation...\n",
      "latitude                                                  37.616889\n",
      "longitude                                               -122.389291\n",
      "category                                            ['Coffee shop']\n",
      "avg_rating                                                      2.1\n",
      "num_of_reviews                                                    8\n",
      "price                                                             $\n",
      "hours             [['Wednesday', 'Open 24 hours'], ['Thursday', ...\n",
      "Name: 863, dtype: object\n",
      "County:  40    San Mateo\n",
      "Name: NAME, dtype: object\n",
      "Price encoding:  [1, 0, 0]\n",
      "County encoding:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Hour encoding:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "example = cafes.iloc[863,:]\n",
    "print(example)\n",
    "print(\"County: \", get_county_name(example['latitude'], example['longitude']))\n",
    "print(\"Price encoding: \", price_to_onehot(example))\n",
    "print(\"County encoding: \", county_to_onehot(example))\n",
    "print(\"Hour encoding: \", hours_to_onehot(example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60e62411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Unix weekday encoding:  [0, 1, 0, 0, 0, 0, 0]\n",
      "Unix hour encoding:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "example = reviews.iloc[863, :]\n",
    "print(\"Unix weekday encoding: \", unix_weekday_to_onehot(example))\n",
    "print(\"Unix hour encoding: \", unix_hour_to_onehot(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8fd0017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE:  0.16932925119017256\n"
     ]
    }
   ],
   "source": [
    "# Basic Model - Global Average\n",
    "global_avg = avg_rating(cafes)\n",
    "total = 0\n",
    "for i,row in cafes.iterrows():\n",
    "    total += (row['avg_rating'] - global_avg)**2\n",
    "\n",
    "print(\"Baseline MSE: \", total/len(cafes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de992e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "example = cafes.iloc[863,:]\n",
    "print(example)\n",
    "print(\"County: \", get_county_name(example['latitude'], example['longitude']))\n",
    "print(\"Price encoding: \", price_to_onehot(example))\n",
    "print(\"County encoding: \", county_to_onehot(example))\n",
    "print(\"Hour encoding: \", hours_to_onehot(example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e62411",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = reviews.iloc[863, :]\n",
    "print(\"Unix weekday encoding: \", unix_weekday_to_onehot(example))\n",
    "print(\"Unix hour encoding: \", unix_hour_to_onehot(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fd0017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
